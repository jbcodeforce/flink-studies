<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/flink-studies/concepts/ rel=canonical><link rel=prev href=..><link href=../coding/getting-started/ rel=next><link rel=icon href=../images/logo-blue.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.2"><title>Flink Key Concepts - Apache and Confluent Flink Studies</title><link rel=stylesheet href=../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../assets/_mkdocstrings.css><link rel=stylesheet href=../extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#quick-reference class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Apache and Confluent Flink Studies" class="md-header__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../images/flink-header-logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Apache and Confluent Flink Studies </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Flink Key Concepts </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class="md-tabs__item md-tabs__item--active"> <a href=.. class=md-tabs__link> Foundations </a> </li> <li class=md-tabs__item> <a href=../cookbook/ class=md-tabs__link> Cookbook </a> </li> <li class=md-tabs__item> <a href=../coding/flink-sql-clients/ class=md-tabs__link> Flink_App_Coding </a> </li> <li class=md-tabs__item> <a href=../methodology/data_as_a_product/ class=md-tabs__link> Methodology </a> </li> <li class=md-tabs__item> <a href=../techno/ccloud-flink/ class=md-tabs__link> Related_Technologies </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-tabs__link> EDA </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Apache and Confluent Flink Studies" class="md-nav__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../images/flink-header-logo.svg alt=logo> </a> Apache and Confluent Flink Studies </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1 checked> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex> <span class=md-ellipsis> Foundations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=true> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Foundations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Flink Key Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Flink Key Concepts </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#quick-reference class=md-nav__link> <span class=md-ellipsis> Quick Reference </span> </a> </li> <li class=md-nav__item> <a href=#why-flink class=md-nav__link> <span class=md-ellipsis> Why Flink? </span> </a> </li> <li class=md-nav__item> <a href=#overview-of-apache-flink class=md-nav__link> <span class=md-ellipsis> Overview of Apache Flink </span> </a> </li> <li class=md-nav__item> <a href=#stream-processing-concepts class=md-nav__link> <span class=md-ellipsis> Stream Processing Concepts </span> </a> <nav class=md-nav aria-label="Stream Processing Concepts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bounded-and-unbounded-data class=md-nav__link> <span class=md-ellipsis> Bounded and unbounded data </span> </a> </li> <li class=md-nav__item> <a href=#dataflow class=md-nav__link> <span class=md-ellipsis> Dataflow </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#runtime-architecture class=md-nav__link> <span class=md-ellipsis> Runtime architecture </span> </a> </li> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State Management </span> </a> <nav class=md-nav aria-label="State Management"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#core-concept-of-state class=md-nav__link> <span class=md-ellipsis> Core Concept of State </span> </a> </li> <li class=md-nav__item> <a href=#types-of-state class=md-nav__link> <span class=md-ellipsis> Types of State </span> </a> </li> <li class=md-nav__item> <a href=#fault-tolerance-and-consistency class=md-nav__link> <span class=md-ellipsis> Fault Tolerance and Consistency </span> </a> </li> <li class=md-nav__item> <a href=#state-backends class=md-nav__link> <span class=md-ellipsis> State Backends </span> </a> </li> <li class=md-nav__item> <a href=#sources-of-knowledge class=md-nav__link> <span class=md-ellipsis> Sources of knowledge </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#windowing class=md-nav__link> <span class=md-ellipsis> Windowing </span> </a> <nav class=md-nav aria-label=Windowing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tumbling-windows class=md-nav__link> <span class=md-ellipsis> Tumbling windows </span> </a> </li> <li class=md-nav__item> <a href=#sliding-windows class=md-nav__link> <span class=md-ellipsis> Sliding windows </span> </a> </li> <li class=md-nav__item> <a href=#session-window class=md-nav__link> <span class=md-ellipsis> Session window </span> </a> </li> <li class=md-nav__item> <a href=#global class=md-nav__link> <span class=md-ellipsis> Global </span> </a> </li> <li class=md-nav__item> <a href=#trigger class=md-nav__link> <span class=md-ellipsis> Trigger </span> </a> </li> <li class=md-nav__item> <a href=#eviction class=md-nav__link> <span class=md-ellipsis> Eviction </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#event-time class=md-nav__link> <span class=md-ellipsis> Event time </span> </a> </li> <li class=md-nav__item> <a href=#watermarks class=md-nav__link> <span class=md-ellipsis> Watermarks </span> </a> <nav class=md-nav aria-label=Watermarks> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=#source-of-information class=md-nav__link> <span class=md-ellipsis> Source of information </span> </a> </li> <li class=md-nav__item> <a href=#classical-issue-due-to-watermark class=md-nav__link> <span class=md-ellipsis> Classical issue due to watermark </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-watermark class=md-nav__link> <span class=md-ellipsis> Monitoring watermark </span> </a> </li> <li class=md-nav__item> <a href=#identify-which-watermark-is-calculated class=md-nav__link> <span class=md-ellipsis> Identify which watermark is calculated </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-skew class=md-nav__link> <span class=md-ellipsis> Data Skew </span> </a> </li> <li class=md-nav__item> <a href=#from-batch-to-real-time class=md-nav__link> <span class=md-ellipsis> From batch to real-time </span> </a> <nav class=md-nav aria-label="From batch to real-time"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-star-schema class=md-nav__link> <span class=md-ellipsis> The star schema </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#source-of-knowledge class=md-nav__link> <span class=md-ellipsis> Source of knowledge </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../coding/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class=md-nav__item> <a href=flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL concepts </span> </a> </li> <li class=md-nav__item> <a href=../labs/ class=md-nav__link> <span class=md-ellipsis> Code&Demos </span> </a> </li> <li class=md-nav__item> <a href=../architecture/agentic_flink/ class=md-nav__link> <span class=md-ellipsis> Agentic applications </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Cookbook </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Cookbook </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cookbook/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../cookbook/considerations/ class=md-nav__link> <span class=md-ellipsis> Considerations </span> </a> </li> <li class=md-nav__item> <a href=../cookbook/cluster_mgt/ class=md-nav__link> <span class=md-ellipsis> Cluster management </span> </a> </li> <li class=md-nav__item> <a href=../cookbook/job_lifecycle/ class=md-nav__link> <span class=md-ellipsis> Job Lifecycle </span> </a> </li> <li class=md-nav__item> <a href=../coding/k8s-deploy/ class=md-nav__link> <span class=md-ellipsis> FKO & CMF Deployment </span> </a> </li> <li class=md-nav__item> <a href=../cookbook/terraform/ class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Terraform </span> </a> </li> <li class=md-nav__item> <a href=../techno/fk-k8s-monitor/ class=md-nav__link> <span class=md-ellipsis> Monitoring </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Flink_App_Coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Flink_App_Coding </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Flink SQL coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Flink SQL coding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../coding/flink-sql-clients/ class=md-nav__link> <span class=md-ellipsis> SQL Clients </span> </a> </li> <li class=md-nav__item> <a href=../coding/flink-sql-1/ class=md-nav__link> <span class=md-ellipsis> Create Table (SQL) </span> </a> </li> <li class=md-nav__item> <a href=../coding/flink-sql-2/ class=md-nav__link> <span class=md-ellipsis> SQL DML </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Java - Python </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Java - Python </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../coding/table-api/ class=md-nav__link> <span class=md-ellipsis> Table API </span> </a> </li> <li class=md-nav__item> <a href=../coding/datastream/ class=md-nav__link> <span class=md-ellipsis> DataStreams API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../coding/udf_sql/ class=md-nav__link> <span class=md-ellipsis> UDFs & PTFs </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Manage CC Flink projects </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_5> <label class=md-nav__link for=__nav_3_5 id=__nav_3_5_label tabindex=0> <span class=md-ellipsis> More advanced topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_5_label aria-expanded=false> <label class=md-nav__title for=__nav_3_5> <span class="md-nav__icon md-icon"></span> More advanced topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../coding/stateful-func/ class=md-nav__link> <span class=md-ellipsis> Stateful function </span> </a> </li> <li class=md-nav__item> <a href=../coding/cep/ class=md-nav__link> <span class=md-ellipsis> Complex Event Processing </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../methodology/data_as_a_product/ class=md-nav__link> <span class=md-ellipsis> Data as a product </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies/methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Migrate to real-time processing tools </span> </a> </li> <li class=md-nav__item> <a href=../methodology/coe/ class=md-nav__link> <span class=md-ellipsis> Center of Excellence </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/flink_project_demos/c360/spark_project/ class=md-nav__link> <span class=md-ellipsis> A C360 data product demo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Related_Technologies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Related_Technologies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../techno/ccloud-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Flink </span> </a> </li> <li class=md-nav__item> <a href=../techno/cp-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Platform for Flink </span> </a> </li> <li class=md-nav__item> <a href=../architecture/kafka/ class=md-nav__link> <span class=md-ellipsis> Kafka Integration </span> </a> </li> <li class=md-nav__item> <a href=../techno/cc-tableflow/ class=md-nav__link> <span class=md-ellipsis> Confluent TableFlow </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/techno/data/#data-related-technologies class=md-nav__link> <span class=md-ellipsis> Apache Iceberg </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/kafka-studies class=md-nav__link> <span class=md-ellipsis> Kafka-studies </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-nav__link> <span class=md-ellipsis> EDA </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#quick-reference class=md-nav__link> <span class=md-ellipsis> Quick Reference </span> </a> </li> <li class=md-nav__item> <a href=#why-flink class=md-nav__link> <span class=md-ellipsis> Why Flink? </span> </a> </li> <li class=md-nav__item> <a href=#overview-of-apache-flink class=md-nav__link> <span class=md-ellipsis> Overview of Apache Flink </span> </a> </li> <li class=md-nav__item> <a href=#stream-processing-concepts class=md-nav__link> <span class=md-ellipsis> Stream Processing Concepts </span> </a> <nav class=md-nav aria-label="Stream Processing Concepts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bounded-and-unbounded-data class=md-nav__link> <span class=md-ellipsis> Bounded and unbounded data </span> </a> </li> <li class=md-nav__item> <a href=#dataflow class=md-nav__link> <span class=md-ellipsis> Dataflow </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#runtime-architecture class=md-nav__link> <span class=md-ellipsis> Runtime architecture </span> </a> </li> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State Management </span> </a> <nav class=md-nav aria-label="State Management"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#core-concept-of-state class=md-nav__link> <span class=md-ellipsis> Core Concept of State </span> </a> </li> <li class=md-nav__item> <a href=#types-of-state class=md-nav__link> <span class=md-ellipsis> Types of State </span> </a> </li> <li class=md-nav__item> <a href=#fault-tolerance-and-consistency class=md-nav__link> <span class=md-ellipsis> Fault Tolerance and Consistency </span> </a> </li> <li class=md-nav__item> <a href=#state-backends class=md-nav__link> <span class=md-ellipsis> State Backends </span> </a> </li> <li class=md-nav__item> <a href=#sources-of-knowledge class=md-nav__link> <span class=md-ellipsis> Sources of knowledge </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#windowing class=md-nav__link> <span class=md-ellipsis> Windowing </span> </a> <nav class=md-nav aria-label=Windowing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tumbling-windows class=md-nav__link> <span class=md-ellipsis> Tumbling windows </span> </a> </li> <li class=md-nav__item> <a href=#sliding-windows class=md-nav__link> <span class=md-ellipsis> Sliding windows </span> </a> </li> <li class=md-nav__item> <a href=#session-window class=md-nav__link> <span class=md-ellipsis> Session window </span> </a> </li> <li class=md-nav__item> <a href=#global class=md-nav__link> <span class=md-ellipsis> Global </span> </a> </li> <li class=md-nav__item> <a href=#trigger class=md-nav__link> <span class=md-ellipsis> Trigger </span> </a> </li> <li class=md-nav__item> <a href=#eviction class=md-nav__link> <span class=md-ellipsis> Eviction </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#event-time class=md-nav__link> <span class=md-ellipsis> Event time </span> </a> </li> <li class=md-nav__item> <a href=#watermarks class=md-nav__link> <span class=md-ellipsis> Watermarks </span> </a> <nav class=md-nav aria-label=Watermarks> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=#source-of-information class=md-nav__link> <span class=md-ellipsis> Source of information </span> </a> </li> <li class=md-nav__item> <a href=#classical-issue-due-to-watermark class=md-nav__link> <span class=md-ellipsis> Classical issue due to watermark </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-watermark class=md-nav__link> <span class=md-ellipsis> Monitoring watermark </span> </a> </li> <li class=md-nav__item> <a href=#identify-which-watermark-is-calculated class=md-nav__link> <span class=md-ellipsis> Identify which watermark is calculated </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-skew class=md-nav__link> <span class=md-ellipsis> Data Skew </span> </a> </li> <li class=md-nav__item> <a href=#from-batch-to-real-time class=md-nav__link> <span class=md-ellipsis> From batch to real-time </span> </a> <nav class=md-nav aria-label="From batch to real-time"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-star-schema class=md-nav__link> <span class=md-ellipsis> The star schema </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#source-of-knowledge class=md-nav__link> <span class=md-ellipsis> Source of knowledge </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>Flink Key Concepts</h1> <p>windowing# Apache Flink - Core Concepts</p> <details class=-> <summary>Version</summary> <ul> <li>Update 07/2025 - Review done with simplification and avoid redundancies.</li> <li>Update - revision 11/23/25</li> <li>2/2026: Refactor content as part of the new cookbok chapter</li> </ul> </details> <h2 id=quick-reference>Quick Reference<a class=headerlink href=#quick-reference title="Permanent link">&para;</a></h2> <ul> <li><a href=#overview-of-apache-flink>Core Concepts</a></li> <li><a href=#stream-processing-concepts>Stream Processing</a></li> <li><a href=#runtime-architecture>Architecture</a></li> <li><a href=#state-management>State Management</a></li> <li><a href=#event-time>Time Handling</a></li> </ul> <h2 id=why-flink>Why Flink?<a class=headerlink href=#why-flink title="Permanent link">&para;</a></h2> <p>Traditional data processing faces key challenges:</p> <ul> <li><strong>Transactional Systems</strong>: Monolithic applications with shared databases create scaling challenges</li> <li><strong>Analytics Systems</strong>: ETL pipelines create stale data and require massive storage and often duplicate data across systems. ETLs extract data from a transactional database, transform it into a common representation (including validation, normalization, encoding, deduplication, and schema transformation), and then load the new records into the target analytical database. These processes are run periodically in batches.</li> </ul> <p>Flink enables <strong>real-time stream processing</strong> with three application patterns:</p> <ol> <li><strong>Event-Driven Applications</strong>: Reactive systems using messaging</li> <li><strong>Data Pipelines</strong>: Low-latency transformation and enrichment </li> <li><strong>Real-Time Analytics</strong>: Immediate computation and action on streaming data</li> </ol> <p>Flink Apps bring stateful processing to serverless. Developers write event handlers in Java (similar to serverless functions) but with annotations for state, timers, and multi-stream correlation. State is automatically partitioned, persisted, and restored. Event-time processing handles late-arriving data correctly. Exactly-once guarantees ensure critical business logic executes reliably. </p> <h2 id=overview-of-apache-flink>Overview of Apache Flink<a class=headerlink href=#overview-of-apache-flink title="Permanent link">&para;</a></h2> <p><a href=https://flink.apache.org>Apache Flink</a> is a distributed stream processing engine for stateful computations over bounded and unbounded data streams. It's become an industry standard due to its performance and comprehensive feature set.</p> <p><strong>Key Features:</strong></p> <ul> <li><strong>Low Latency Processing:</strong> Offers event time semantics for consistent and accurate results, even with out-of-order events.</li> <li><strong>Exactly-Once Consistency:</strong> Ensures reliable state management to avoid duplicates and not loosing message.</li> <li><strong>High Throughput:</strong> Achieves millisecond latencies while processing millions of events per second.</li> <li><strong>Powerful APIs:</strong> Provides APIs for operations such as map, reduce, join, window, split, and connect.</li> <li><strong>Fault Tolerance and High Availability:</strong> Supports failover for task manager nodes, eliminating single points of failure.</li> <li><strong>Multilingual Support:</strong> Enables streaming logic implementation in Java, Scala, Python, and SQL.</li> <li><strong>Extensive Connectors:</strong> Integrates seamlessly with various systems, including Kafka, Cassandra, Pulsar, Elasticsearch, File system, JDBC complain Database, HDFS and S3.</li> <li><strong>Kubernetes Native:</strong> Supports containerization and deployment on Kubernetes with dedicated k8s operator to manage session job or application as well as job and task managers.</li> <li><strong>Dynamic Code Updates:</strong> Allows for application code updates and job migrations across different Flink clusters without losing application state.</li> <li><strong>Batch Processing:</strong> Also transparently support traditional batch processing workloads as reading at rest table becomes a stream in Flink</li> </ul> <h2 id=stream-processing-concepts>Stream Processing Concepts<a class=headerlink href=#stream-processing-concepts title="Permanent link">&para;</a></h2> <p>A Flink application runs as a <strong>job</strong> - a processing pipeline structured as a directed acyclic graph (DAG) with:</p> <ul> <li><strong>Sources</strong>: Read from streams (Kafka, Kinesis, Queue, CDC etc.)</li> <li><strong>Operators</strong>: Transform, filter, enrich data</li> <li><strong>Sinks</strong>: Write results to external systems</li> </ul> <figure> <img alt=1 src=diagrams/dag.drawio.png width=600> <figcaption>Data flow as directed acyclic graph</figcaption> </figure> <p>Operations can run in parallel across partitions. Some operators (like <strong>Group By</strong>) require data reshuffling or repartitioning.</p> <h3 id=bounded-and-unbounded-data>Bounded and unbounded data<a class=headerlink href=#bounded-and-unbounded-data title="Permanent link">&para;</a></h3> <p>A Stream is a sequence of events, bounded or unbounded:</p> <figure> <img alt=3 src=diagrams/streaming.drawio.png width=600> <figcaption>Bounded and unbounded event sequence</figcaption> </figure> <p>Apache Flink supports batch processing by processing all the data in one job with bounded dataset. It is used when we need all the data, to assess trend, develop AI model, and with a focus on throughput instead of latency. Jobs are run when needed, on input that can be pre-sorted by time or by any other key.</p> <p>The results are reported at the end of the job execution. Any failure means to do of full restart of the job.</p> <p>Hadoop was designed to do batch processing. Flink has capability to replace the Hadoop map-reduce processing.</p> <p>When latency is a major requirements, like monitoring and alerting, fraud detection then streaming is the only choice.</p> <h3 id=dataflow>Dataflow<a class=headerlink href=#dataflow title="Permanent link">&para;</a></h3> <p>In <a href=https://nightlies.apache.org/flink/flink-docs-release-2.1/learn-flink/overview/#stream-processing>Flink 2.1.x</a>, applications are composed of streaming dataflows. Dataflow can consume from Kafka, Kinesis, Queue, and any data sources. A typical high level view of Flink app is presented in figure below:</p> <figure> <img alt=4 src=https://nightlies.apache.org/flink/flink-docs-release-2.1/fig/flink-application-sources-sinks.png> <figcaption>A Flink application - src: apache Flink product doc</figcaption> </figure> <p>Stream processing includes a set of functions to transform data, and to produce a new output stream. An operator in Flink is a component that performs a specific operation on the data stream. Operations can be transformations (e.g., map, filter, reduce); an action (e.g., print, save); or, a source or sink. Intermediate steps compute rolling aggregations like min, max, mean, or collect and buffer records in time window to compute metrics on a finite set of events. </p> <figure> <img alt=5 src=https://nightlies.apache.org/flink/flink-docs-release-2.1/fig/program_dataflow.svg width=600> <figcaption>Streaming Dataflow src: apache Flink product doc</figcaption> </figure> <p>Data is partitioned for parallel processing.Flink performs computations using tasks, subtasks and operators. Each stream has multiple partitions, and each operator has multiple tasks for scalability. Tasks are the basic unit of execution in Flink. A task represents a piece of work that gets scheduled and executed by the Flink runtime. </p> <p>Each task is responsible for executing a specific part of the data processing logic defined by Flink. Tasks are parallelizable, meaning you can have multiple instances of a task running in parallel to process data streams more efficiently. A subtask in Flink is a parallel instance of a task. A task can be divided into multiple subtasks that can all be running at the same time. Each subtask processes a portion of the data leading to more efficient data processing. </p> <figure> <img alt=6 src=https://nightlies.apache.org/flink/flink-docs-release-2.1/fig/parallel_dataflow.svg width=600> <figcaption>Distributed processing src: apache Flink product doc</figcaption> </figure> <p>Operations like <strong>GROUP BY</strong> require data reshuffling across network, which can be costly but enables distributed aggregation.</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>results</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=k>SELECT</span><span class=w> </span><span class=k>key</span><span class=p>,</span><span class=w> </span><span class=k>COUNT</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>events</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=k>WHERE</span><span class=w> </span><span class=n>color</span><span class=w> </span><span class=o>&lt;&gt;</span><span class=w> </span><span class=n>blue</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=k>GROUP</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=k>key</span><span class=p>;</span>
</span></code></pre></div> <h2 id=runtime-architecture>Runtime architecture<a class=headerlink href=#runtime-architecture title="Permanent link">&para;</a></h2> <p>Flink consists of a <strong>Job Manager</strong> and <code>n</code> <strong>Task Managers</strong> deployed on <code>k</code> hosts. </p> <figure> <img alt=1 src=diagrams/flink_basic_arch.drawio.png> <figcaption>Main Flink Components</figcaption> </figure> <p>Client applications compile batch or streaming applications into a dataflow graph. Client submits the DAG to the JobManager. The <strong>JobManager</strong> controls the execution of one or more applications. Developers submit their application (jar file or SQL statements) via CLI, REST call or k8s manifest. Job Manager receives the Flink application for execution and builds a Task Execution Graph from the defined <strong>JobGraph</strong>. It manages job submission which parallelizes the job and distributes slices of <a href=https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html>the Data Stream</a> flow, the developers have defined. Each parallel slice of the job is a task that is executed in a <strong>task slot</strong>. </p> <p>Once the job is submitted, the <strong>Job Manager</strong> is scheduling the job to different task slots within the <strong>Task Manager</strong>. The Job manager may create resources from a computer pool, or when deployed on kubernetes, it creates pods. </p> <p>The <strong>Resource Manager</strong> manages Task Slots and leverages an underlying orchestrator, like Kubernetes or Yarn (deprecated).</p> <p>A <strong>Task slot</strong> is the unit of work executed on CPU. The <strong>Task Managers</strong> execute the actual stream processing logic. There are multiple task managers running in a cluster. The number of slots limits the number of tasks a TaskManager can execute. After it has been started, a TaskManager registers its slots to the ResourceManager:</p> <figure> <img alt=2 src=images/flink-components.png> <figcaption>Sequence flow from job submission</figcaption> </figure> <p>The <strong>Dispatcher</strong> exposes API to submit applications for execution. It hosts the user interface too.</p> <p>Once the job is running, the Job Manager is responsible to coordinate the activities of the Flink cluster, like checkpointing, and restarting task manager that may have failed.</p> <p>Tasks are loading the data from sources, do their own processing and then send data among themselves for repartitioning and rebalancing, to finally push results out to the sinks.</p> <p>When Flink is not able to process a real-time event, it may have to buffer it, until other necessary data has arrived. This buffer has to be persisted in longer storage, so data are not lost if a task manager fails and has to be restarted. In batch mode, the job can reload the data from the beginning. In batch the results are computed once the job is done (count the number of record like <code>select count(*) AS</code>count<code>from bounded_pageviews;</code> return one result), while in streaming mode, each event may be the last one received, so results are produced incrementally, after every events or after a certain period of time based on timers.</p> <details class=-> <summary>Parameters</summary> <ul> <li>taskmanager.numberOfTaskSlots: 2</li> </ul> </details> <p>Only one Job Manager is active at a given point of time, and there may be <code>n</code> Task Managers. It is a single point of failure, but it startes quickly and can leverage the checkpoints data to restart its processing.</p> <p>There are different <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/ops/deployment/ >deployment models</a>: </p> <ul> <li>Deploy on executing cluster, this is the <strong>session mode</strong>. Use <strong>session</strong> cluster to run multiple jobs: we need a separate JobManager container for that. </li> <li><strong>Per job</strong> mode: spin up a cluster per job submission. This provides better resource isolation. </li> <li><strong>Application mode</strong>: creates a cluster per app with the <code>main()</code> function executed on the JobManager. It can include multiple jobs but they run inside the app. It allows for saving the required CPU cycles, but also save the bandwidth required for downloading the dependencies locally.</li> </ul> <p>Flink can run on any common resource manager like Hadoop Yarn, Mesos, or Kubernetes. For development purpose, we can use docker images to deploy a <strong>Session</strong> or <strong>Job cluster</strong>.</p> <p>See also <a href=../coding/k8s-deploy/ >deployment to Kubernetes</a></p> <p>The new K8s operator, deploys and monitors Flink Application and Session deployments.</p> <h2 id=state-management>State Management<a class=headerlink href=#state-management title="Permanent link">&para;</a></h2> <p>In Flink, <a href=https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/stateful-stream-processing/ >state</a> consists of information that an operator remembers about past events, which is used to influence the processing of future events.</p> <h3 id=core-concept-of-state>Core Concept of State<a class=headerlink href=#core-concept-of-state title="Permanent link">&para;</a></h3> <ul> <li> <p>Stateful operations are required for many common use cases, such as:</p> <ul> <li><strong>Windowing:</strong> Aggregating events over time (e.g., sum of sales per minute).</li> <li><strong>Pattern Detection:</strong> Tracking a sequence of events to find specific patterns.</li> <li><strong>Machine Learning:</strong> Updating model parameters based on a stream of data.</li> <li><strong>Analytics:</strong> Maintaining counters or profiles for unique users.</li> </ul> </li> <li> <p>We can dissociate different type of operations:</p> <ul> <li><strong>Stateless Operations</strong> process each event independently without retaining information:<ul> <li>Basic operations: <code>INSERT</code>, <code>SELECT</code>, <code>WHERE</code>, <code>FROM</code> </li> <li>Scalar/table functions, projections, filters</li> </ul> </li> <li><strong>Stateful Operations</strong> maintain state across events for complex processing:<ul> <li><code>JOIN</code> operations (except <code>CROSS JOIN UNNEST</code>)</li> <li><code>GROUP BY</code> aggregations (windowed/non-windowed)</li> <li><code>OVER</code> aggregations and <code>MATCH_RECOGNIZE</code> patterns</li> </ul> </li> </ul> </li> </ul> <h3 id=types-of-state>Types of State<a class=headerlink href=#types-of-state title="Permanent link">&para;</a></h3> <p>Flink distinguishes between two main categories of state:</p> <ul> <li><strong>Managed State:</strong> Handled by the Flink runtime. Flink manages the storage, rescaling, and fault tolerance of this state.</li> <li><strong>Raw State:</strong> Handled by the user in their own data structures. It is generally not recommended as Flink cannot automatically manage it during rescaling.</li> </ul> <p>Within Managed State, there are several sub-types:</p> <ul> <li> <p><strong>Keyed State:</strong> Tied to a specific key (e.g., a user ID). It is partitioned across the cluster so that each key's state is handled by exactly one parallel task. Flink maintains one state instance per key value and Flink partitions all records with the same key to the operator task that maintains the state for this key. The key-value map is sharded across all parallel tasks:</p> <p><figure markdown=span> <img alt src=images/key-state.png width=600> <figcaption>Keyes states</figcaption> </figure></p> <p>Each task maintains its state locally to improve latency. For small state, the state backends will use JVM heap, but for larger state RocksDB is used. A <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/state_backends/ ><strong>state backend</strong></a> takes care of checkpointing the state of a task to a remote and persistent storage.</p> </li> <li> <p><strong>Operator State:</strong> Tied to a parallel operator instance rather than a key. It is often used for source/sink connectors (e.g., tracking Kafka offsets).</p> </li> <li><strong>Broadcast State</strong>: A special type of operator state where the state is duplicated across all parallel tasks of an operator.</li> </ul> <p>Flink keeps state of its processing for Fault tolerance. It fact, Flink uses stream replay and checkpointing. </p> <p>All data maintained by a task and used to compute the results of a function belong to the state of the task. Function may use <k,v> pairs to store values, and may implement the ChekpointedFunctions to make local state fault tolerant.</p> <p>While processing the data, the task can read and update its state and computes its results based on its input data and state.</p> <p>State management may address very large states, and no state is lost in case of failures.</p> <p>Within a DAG, each operator needs to register its state. <strong>Operator state</strong> is scoped to an operator task: all records processed by the same parallel task have access to the same state.</p> <p>State can grow over time. Local state persistence improves latency while remote checkpointing ensures fault tolerance.</p> <figure> <img alt=7 src=diagrams/flink-rt-processing.drawio.png width=600> <figcaption>Flink and Kafka integration with state management</figcaption> </figure> <p>Flink ensures fault tolerance through checkpoints and savepoints that persistently store application state.</p> <h3 id=fault-tolerance-and-consistency>Fault Tolerance and Consistency<a class=headerlink href=#fault-tolerance-and-consistency title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Checkpoints:</strong> Flink periodically takes distributed snapshots of the state and stores them in durable storage.</p> </li> <li> <p><strong>Exactly-once Semantics:</strong> By combining checkpoints with replayable data sources, Flink guarantees that each event affects the state exactly once, even in the event of a failure.</p> </li> <li> <p><strong>Savepoints:</strong> These are manually triggered snapshots used for operational tasks like application upgrades, A/B testing, or migrating to a different cluster.</p> </li> </ul> <p><a href=../cookbook/considerations/#high-availability>See deeper explanations in the cookbook chapter</a></p> <h3 id=state-backends>State Backends<a class=headerlink href=#state-backends title="Permanent link">&para;</a></h3> <p>State backends determine how the state is physically stored. Options typically include:</p> <ul> <li><strong>HashMap State Backend:</strong> Stores state as objects on the JVM heap (very fast, but limited by memory).</li> <li><strong>Embedded RocksDB:</strong> Stores state in an embedded database on local disk. <a href=https://rocksdb.org/ >RocksDB</a> is a key-value store based on Log-Structured Merge-Trees (LSM Trees). Flink organizes state into "Key Groups." Each RocksDB instance on a TaskManager handles a specific set of these groups. It saves asynchronously. Serializes using bytes. But there is a limit to the size per key and valye of 2^31 bytes. Supports incremental checkpoints which is key for maintaining performance as state grows into the terabytes.<ul> <li>The process: When an operator updates state, it writes to the RocksDB MemTable and a Write-Ahead Log (WAL). Once the MemTable is full, it is flushed to disk as a static SST file.</li> <li>ForStState uses tree structured k-v store. May use object storage for remote file systems. Allows Flink to scale the state size beyond the local disk capacity of the TaskManager. </li> <li><code>HashMapStateBackend</code> use Java heap to keep state, as java object. So unsafe to reuse!.</li> </ul> </li> <li><strong>ForSt (Disaggregated):</strong> The 2.x preference for cloud-native scaling and fast recovery, by using Distributed File Systems (DFS).</li> </ul> <h3 id=sources-of-knowledge>Sources of knowledge<a class=headerlink href=#sources-of-knowledge title="Permanent link">&para;</a></h3> <ul> <li><a href=https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/stateful-stream-processing/ >Stateful processing - Apache Flink documentation</a>.</li> <li><a href=https://docs.confluent.io/cloud/current/flink/concepts/overview.html#id2>Confluent state management documentation.</a></li> <li><a href=https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/state/ >See 'working with state' from Flink documentation</a>.</li> </ul> <h2 id=windowing>Windowing<a class=headerlink href=#windowing title="Permanent link">&para;</a></h2> <p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/dev/stream/operators/windows.html>Windows</a> group stream events into finite buckets for processing. Flink provides window table-valued functions (TVF): Tumbling, Hop, Cumulate, Session.</p> <h3 id=tumbling-windows>Tumbling windows<a class=headerlink href=#tumbling-windows title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Tumbling</strong> window assigns events to non-overlapping buckets of fixed size. Records are assigned to the window based on an event-time attribute field, specified by the DESCRIPTOR() function. Once the window boundary is crossed, all events within that window are sent to an evaluation function for processing. </p> </li> <li> <p><strong>Count-based tumbling</strong> windows define how many events are collected before triggering evaluation. </p> </li> <li> <p><strong>Time-based tumbling</strong> windows define time interval (e.g., n seconds) during which events are collected. The amount of data within a window can vary depending on the incoming event rate. <div class="language-java highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=p>.</span><span class=na>keyBy</span><span class=p>(...).</span><span class=na>window</span><span class=p>(</span><span class=n>TumblingProcessingTimeWindows</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=n>Time</span><span class=p>.</span><span class=na>seconds</span><span class=p>(</span><span class=mi>2</span><span class=p>)))</span>
</span></code></pre></div></p> <p>in SQL:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1>-- computes the sum of the price in the orders table within 10-minute tumbling windows</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=k>SELECT</span><span class=w> </span><span class=n>window_start</span><span class=p>,</span><span class=w> </span><span class=n>window_end</span><span class=p>,</span><span class=w> </span><span class=k>SUM</span><span class=p>(</span><span class=n>price</span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=o>`</span><span class=k>sum</span><span class=o>`</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=k>FROM</span><span class=w> </span><span class=k>TABLE</span><span class=p>(</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=w>    </span><span class=n>TUMBLE</span><span class=p>(</span><span class=k>TABLE</span><span class=w> </span><span class=o>`</span><span class=n>examples</span><span class=o>`</span><span class=p>.</span><span class=o>`</span><span class=n>marketplace</span><span class=o>`</span><span class=p>.</span><span class=o>`</span><span class=n>orders</span><span class=o>`</span><span class=p>,</span><span class=w> </span><span class=k>DESCRIPTOR</span><span class=p>(</span><span class=err>$</span><span class=n>rowtime</span><span class=p>),</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=s1>&#39;10&#39;</span><span class=w> </span><span class=n>MINUTES</span><span class=p>))</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=k>GROUP</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>window_start</span><span class=p>,</span><span class=w> </span><span class=n>window_end</span><span class=p>;</span>
</span></code></pre></div> </li> </ul> <figure> <img alt=8 src=images/tumbling.png width=500> <figcaption>Tumbling window concept</figcaption> </figure> <ul> <li>See example <a href=https://github.com/jbcodeforce/flink-studies/blob/master/flink-java/my-flink/src/main/java/jbcodeforce/windows/TumblingWindowOnSale.java>TumblingWindowOnSale.java</a> in my-fink folder and to test it, do the following:</li> </ul> <div class="language-shell highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Start the SaleDataServer that starts a server on socket 9181 and will read the avg.txt file and send each line to the socket</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>java<span class=w> </span>-cp<span class=w> </span>target/my-flink-1.0.0-SNAPSHOT.jar<span class=w> </span>jbcodeforce.sale.SaleDataServer
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># inside the job manager container started with </span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=sb>`</span>flink<span class=w> </span>run<span class=w> </span>-d<span class=w> </span>-c<span class=w> </span>jbcodeforce.windows.TumblingWindowOnSale<span class=w> </span>/home/my-flink/target/my-flink-1.0.0-SNAPSHOT.jar<span class=sb>`</span>.
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=c1># The job creates the data/profitPerMonthWindowed.txt file with accumulated sale and number of record in a 2 seconds tumbling window</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=o>(</span>June,Bat,Category5,154,6<span class=o>)</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=o>(</span>August,PC,Category5,74,2<span class=o>)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=o>(</span>July,Television,Category1,50,1<span class=o>)</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=o>(</span>June,Tablet,Category2,142,5<span class=o>)</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=o>(</span>July,Steamer,Category5,123,6<span class=o>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>...
</span></code></pre></div> <h3 id=sliding-windows>Sliding windows<a class=headerlink href=#sliding-windows title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Sliding</strong> windows allows for overlapping periods, meaning an event can belong to multiple buckets. This is particularly useful for capturing trends over time. The window sliding time parameter defines the duration of the window and the interval at which new windows are created. For example, in the following code snippet defines a new 2-second window is created every 1 second:</p> <div class="language-java highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=p>.</span><span class=na>keyBy</span><span class=p>(...).</span><span class=na>window</span><span class=p>(</span><span class=n>SlidingProcessingTimeWindows</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=n>Time</span><span class=p>.</span><span class=na>seconds</span><span class=p>(</span><span class=mi>2</span><span class=p>),</span><span class=w> </span><span class=n>Time</span><span class=p>.</span><span class=na>seconds</span><span class=p>(</span><span class=mi>1</span><span class=p>)))</span>
</span></code></pre></div> <p>As a result, each event that arrives during this period will be included in multiple overlapping windows, enabling more granular analysis of the data stream.</p> </li> </ul> <figure> <img alt=9 src=images/sliding.png width=500> <figcaption>Sliding window concept</figcaption> </figure> <h3 id=session-window>Session window<a class=headerlink href=#session-window title="Permanent link">&para;</a></h3> <p><strong>Session</strong> window begins when the data stream processes records and ends when there is a defined period of inactivity. The inactivity threshold is set using a timer, which determines how long to wait before closing the window.</p> <div class="language-java highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=p>.</span><span class=na>keyBy</span><span class=p>(...).</span><span class=na>window</span><span class=p>(</span><span class=n>ProcessingTimeSessionWindows</span><span class=p>.</span><span class=na>withGap</span><span class=p>(</span><span class=n>Time</span><span class=p>.</span><span class=na>seconds</span><span class=p>(</span><span class=mi>5</span><span class=p>)))</span>
</span></code></pre></div> <p>The operator creates one window for each data element received. If there is a gap of 5 seconds without new events, the window will close. This makes session windows particularly useful for scenarios where you want to group events based on user activity or sessions of interaction, capturing the dynamics of intermittent data streams effectively.</p> <figure> <img alt=10 src=images/session.png width=500> <figcaption>Session window concept</figcaption> </figure> <h3 id=global>Global<a class=headerlink href=#global title="Permanent link">&para;</a></h3> <ul> <li><strong>Global</strong>: One window per key, requires explicit triggers</li> </ul> <p><a href=https://docs.confluent.io/cloud/current/flink/reference/queries/window-tvf.html>See Windowing TVF documentation</a>.</p> <div class="language-java highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=p>.</span><span class=na>keyBy</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=p>.</span><span class=na>window</span><span class=p>(</span><span class=n>GlobalWindows</span><span class=p>.</span><span class=na>create</span><span class=p>())</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=p>.</span><span class=na>trigger</span><span class=p>(</span><span class=n>CountTrigger</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>
</span></code></pre></div> <p><a href=https://docs.confluent.io/cloud/current/flink/reference/queries/window-tvf.html>See Windowing Table-Valued Functions details in Confluent documentation</a>.</p> <h3 id=trigger>Trigger<a class=headerlink href=#trigger title="Permanent link">&para;</a></h3> <p>A <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/dev/stream/operators/windows.html#triggers>Trigger</a> in Flink, determines when a window is ready to be processed. </p> <p>Each window has a default trigger associated with it. For example, a tumbling window might have a default trigger set to 2 seconds, while a global window requires an explicit trigger definition.</p> <p>You can implement custom triggers by creating a class that implements the Trigger interface, which includes methods such as onElement(..), onEventTime(..), and onProcessingTime(..).</p> <p>Flink provides several default triggers::</p> <ul> <li><strong>EventTimeTrigger</strong> fires based upon progress of event time</li> <li><strong>ProcessingTimeTrigger</strong> fires based upon progress of processing time</li> <li><strong>CountTrigger</strong> fires when # of elements in a window exceeds a specified parameter.</li> <li><strong>PurgingTrigger</strong> is used for purging the window, allowing for more flexible management of state.</li> </ul> <h3 id=eviction>Eviction<a class=headerlink href=#eviction title="Permanent link">&para;</a></h3> <p><strong>Evictor</strong> is used to remove elements from a window either after the trigger fires or before/after the window function is applied. The specific logic for removing elements is application-specific and can be tailored to meet the needs of your use case.</p> <p>The predefined evictors: </p> <ul> <li><strong>CountEvictor</strong> removes elements based on a specified count, allowing for fine control over how many elements remain in the window.</li> <li><strong>DeltaEvictor</strong> evicts elements based on the difference between the current and previous counts, useful for scenarios where you want to maintain a specific change threshold.</li> <li><strong>TimeEvictor</strong> removes elements based on time, allowing you to keep only the most recent elements within a given time frame.</li> </ul> <h2 id=event-time>Event time<a class=headerlink href=#event-time title="Permanent link">&para;</a></h2> <p><strong>Time</strong> is a central concept in stream processing and can have different interpretations based on the context of the flow or environment:</p> <ul> <li><strong>Processing Time</strong> refers to the system time of the machine executing the task. It offers the best performance and lowest latency since it relies on the local clock. But it may lead to no deterministic results due to factors like ingestion delays, parallel execution, clock synch, backpressure...</li> <li><strong>Event Time</strong> is the timestamp embedded in the record at the event source level. Using event-time ensures consistent and deterministic results, regardless of the order in which events are processed. This is crucial for accurately reflecting the actual timing of events.</li> <li><strong>Ingestion Time</strong> denotes the time when an event enters the Flink system. It captures the latency introduced during the event's journey into the processing framework.</li> </ul> <p>In any time window, the order of arrival may not be guarantee, and some events with an older timestamp may fall outside of the time window boundaries. To address this challenge, particularly when computing aggregates, it's essential to ensure that all relevant events have arrived within the intended time frame.</p> <p>The watermark serves as a heuristic for this purpose.</p> <h2 id=watermarks>Watermarks<a class=headerlink href=#watermarks title="Permanent link">&para;</a></h2> <p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/dev/event_timestamps_watermarks.html>Watermarks</a> are special markers indicating event-time progress in streams to keep track of how time progress and to handle out-of-order records. This is the core mechanims to trigger computation at <code>event-time</code>.<br> They determine when windows can safely close by estimating when all events for a time period have arrived.</p> <h3 id=key-concepts>Key Concepts<a class=headerlink href=#key-concepts title="Permanent link">&para;</a></h3> <ul> <li>Generated in the data stream at regular intervals, they are part of the source operator processing or immediately after it. Each parallel subtask of the source typically generates its watermarks independently, based on the events it processes. This is especially important for partitioned sources like Kafka, where each source subtask might read from one or more partitions. </li> <li>Watermark generation logic is defined using a WatermarkStrategy. This strategy is typically applied directly when you define the data source. It tells Flink how to extract the event time timestamp from each incoming data record. And it determines how to generate the actual watermark based on those timestamps. <div class="language-java highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=n>StreamExecutionEnvironment</span><span class=w> </span><span class=n>env</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>StreamExecutionEnvironment</span><span class=p>.</span><span class=na>getExecutionEnvironment</span><span class=p>();</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=w>    </span><span class=c1>// 1. Define the Watermark Strategy</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=w>    </span><span class=n>WatermarkStrategy</span><span class=o>&lt;</span><span class=n>MyEvent</span><span class=o>&gt;</span><span class=w> </span><span class=n>watermarkStrategy</span><span class=w> </span><span class=o>=</span><span class=w> </span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=w>        </span><span class=n>WatermarkStrategy</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=w>            </span><span class=c1>// This strategy is ideal for out-of-order data streams.</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=w>            </span><span class=c1>// It allows events up to 5 seconds late (out-of-order) to be processed.</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=w>            </span><span class=p>.</span><span class=o>&lt;</span><span class=n>MyEvent</span><span class=o>&gt;</span><span class=n>forBoundedOutOfOrderness</span><span class=p>(</span><span class=n>Duration</span><span class=p>.</span><span class=na>ofSeconds</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=w>            </span><span class=c1>// 2. Define how to extract the event timestamp from the record</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=w>            </span><span class=p>.</span><span class=na>withTimestampAssigner</span><span class=p>((</span><span class=n>event</span><span class=p>,</span><span class=w> </span><span class=n>timestamp</span><span class=p>)</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>event</span><span class=p>.</span><span class=na>getEventTime</span><span class=p>());</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=w>    </span><span class=c1>// 3. Apply the Strategy directly to the Source Connector</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=w>    </span><span class=n>DataStream</span><span class=o>&lt;</span><span class=n>MyEvent</span><span class=o>&gt;</span><span class=w> </span><span class=n>stream</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>env</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=w>        </span><span class=p>.</span><span class=na>fromSource</span><span class=p>(</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=w>            </span><span class=c1>// In a real application, this would be a KafkaSource, FileSource, etc.</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=w>            </span><span class=c1>// Here, we use a simple collection source for demonstration.</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a><span class=w>            </span><span class=k>new</span><span class=w> </span><span class=n>DummyEventSource</span><span class=p>(),</span><span class=w> </span><span class=c1>// Assuming a custom Flink Source implementation</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a><span class=w>            </span><span class=n>watermarkStrategy</span><span class=p>,</span><span class=w> </span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a><span class=w>            </span><span class=s>&quot;My Event Source&quot;</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a><span class=w>        </span><span class=p>);</span>
</span></code></pre></div></li> <li>Watermarks flow downstream alongside the data records</li> <li>Watermark timestamp = largest seen timestamp - estimated out-of-orderness. This timestamp are always increasing. </li> <li>Events arriving after watermarks are considered late and typically discarded</li> <li>The default strategy is designed for large-scale production workloads, requiring a significant volume of data (around 250 events per partition) before advancing the watermark and emitting results.</li> <li>Essential for triggering window computations in event-time processing</li> </ul> <figure> <img alt=11 src=diagrams/watermark.drawio.png> <figcaption>Watermark concept</figcaption> </figure> <p>Within a window, states are saved on disk and need to be cleaned once the window is closed. The watermark is the limit from where the Java garbage collection may occur. </p> <p>The out-of-orderness estimation serves as an educated guess and is defined for each individual stream. Watermarks are essential for comparing timestamps of events, allowing the system to assert that no earlier events will arrive after the watermark's timestamp.</p> <p>Watermarks are crucial when dealing with multiple sources. In scenarios involving IoT devices and network latency, it's possible to receive an event with an earlier timestamp even after the operator has already processed events with that timestamp from other sources. Importantly, watermarks are applicable to any timestamps and are not limited to window semantics.</p> <p>When working with Kafka topic partitions, the absence of watermarks may represent some challenges. Watermarks are generated independently for each stream and partition. When two partitions are combined, the resulting watermark will be the oldest of the two (min value), reflecting the point at which the system has complete information. If one partition stops receiving new events, the watermark for that partition will not progress. To ensure that processing continues over time, an idle timeout configuration can be implemented.</p> <p>Each task has its own watermark, and at the arrival of a new watermark, it checks if it needs to advance its own watermark. When it is advanced, the task performs all triggered computations and emits all result records. The watermark is broadcasted to all output of the task.</p> <p>The watermark of a task is the mininum of all per-connection watermarks. Task with multiple input, like JOINs or UNIONs maintains a single watermark, which is the minimum between the input watermarks.</p> <p>Additionally, it is possible to configure the system to accept late events by specifying an <code>allowed lateness</code> period. This defines how late an element can arrive before it is discarded. Flink maintains the state of the window until the allowed lateness time has expired, allowing for flexible handling of late-arriving data while ensuring that the processing remains efficient and accurate.</p> <p>When using processing time, the watermark advances at regular intervals, typically every second. Events within the window are emitted for processing, once the watermark surpasses the end of that window.</p> <p>Parallel watermarking is an example of getting data from 4 partitions with 2 kafka consumers and 2 windows:</p> <figure> <img alt src=diagrams/parallel-watermark.drawio.png> <figcaption>Parallel watermarking</figcaption> </figure> <p>Shuffling is done as windows are computing some COUNT or GROUP BY operations. Event A arriving at 3:13, and B[3:20] on green partitions, and are processed by Window 1 which considers 60 minutes time between 3:00 and 4:00. </p> <p>The source connector sends a Watermark for each partition independently. If the out-of-orderness is set to be 5 minutes, a watermark is created with a timestamp 3:08 = 3:13 - 5 (partition 0) and at 3:15 (3:20 - 5) for partition 1. The generator sends the minimum of both. The timestamp reflects how complete the stream is so far: it could not be no more completed than the further behind which was event at 3:13, </p> <p>In the case of a partition does not get any events, as there is no watermark generated for this partition, it may mean the watermark does no advance, and as a side effect it prevents windows from producing events. To avoid this problem, we need to balance kafka partitions so none are empty or idle, or configure the watermarking to use idleness detection.</p> <h3 id=source-of-information>Source of information<a class=headerlink href=#source-of-information title="Permanent link">&para;</a></h3> <ul> <li><a href>Confluent documentation</a></li> <li><a href=https://docs.confluent.io/cloud/current/flink/concepts/timely-stream-processing.html>Interesting enablement from Confluent, David Anderson</a></li> <li><a href="https://flink-watermarks.wtf/?utm_source=cd_newsletter">An animated webapp to explain the Watermark concepts</a>.</li> </ul> <h3 id=classical-issue-due-to-watermark>Classical issue due to watermark<a class=headerlink href=#classical-issue-due-to-watermark title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Records may not being seen in output table or topic</strong>. When testing with only a few events, this fails to meet the initial "safety margin" of 250 events per partition. This causes the system to apply a massive 7-day default margin, which stalls the watermark indefinitely and prevents time windows from ever closing and producing a result.</p> </li> <li> <p><strong>Stalled Joins with Idle Sources</strong>: When joining two streams, if one stream is idle or has very old data, its watermark remains far in the past. The join operator's watermark becomes the minimum of the two, effectively stalling the entire query and preventing any new join results from being produced, even when one stream is active.</p> </li> <li><strong>Losing the Last Message:</strong> In a sparse stream of events, the very last event is correctly placed in its time window but remains buffered. Because no new event ever arrives to advance the watermark past the end of that final window, the window never closes, and the result for the last message is never produced, making it seem like Flink lost data.</li> </ul> <h3 id=monitoring-watermark>Monitoring watermark<a class=headerlink href=#monitoring-watermark title="Permanent link">&para;</a></h3> <p>The following metrics are used at the operator and task level</p> <ul> <li><code>currentInputWatermark</code>: the last watermark received by the operator in its n inputs.</li> <li><code>currentOutputWatermark</code>: last emitted watermark by the operator</li> <li><code>watermarkAlignmentDrift</code>: current drift from the minimal watermakr emitted by all sources beloging to the same watermark group.</li> </ul> <p>Watermarks can be seen in Apache flink Console. </p> <details class=info open=open> <summary>Confluent Cloud for Flink</summary> <ul> <li>The default watermark strategy is set to 180ms.</li> <li>There is a support for configurable late data handling to DLQ to avoid data drop. Developers choose between three options: "pass," "drop," or "send to a dead letter queue (DLQ)</li> </ul> </details> <h3 id=identify-which-watermark-is-calculated>Identify which watermark is calculated<a class=headerlink href=#identify-which-watermark-is-calculated title="Permanent link">&para;</a></h3> <p>The approach is to add a virtual column to keep the Kafka partition number:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=k>ALTER</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=o>&lt;</span><span class=k>table_name</span><span class=o>&gt;</span><span class=w> </span><span class=k>ADD</span><span class=w> </span><span class=n>_part</span><span class=w> </span><span class=nb>INT</span><span class=w> </span><span class=n>METADATA</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=s1>&#39;partition&#39;</span><span class=w> </span><span class=n>VIRTUAL</span><span class=p>;</span>
</span></code></pre></div> <p>then assess if there is a value on the "Operator Watermark" column with</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=k>SELECT</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=w>  </span><span class=o>*</span><span class=p>,</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=w>  </span><span class=n>_part</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=o>`</span><span class=k>Row</span><span class=w> </span><span class=n>Partition</span><span class=o>`</span><span class=p>,</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=w>  </span><span class=err>$</span><span class=n>rowtime</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=o>`</span><span class=k>Row</span><span class=w> </span><span class=k>Timestamp</span><span class=o>`</span><span class=p>,</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=w>  </span><span class=n>CURRENT_WATERMARK</span><span class=p>(</span><span class=err>$</span><span class=n>rowtime</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=o>`</span><span class=k>Operator</span><span class=w> </span><span class=n>Watermark</span><span class=o>`</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=k>FROM</span><span class=w>  </span><span class=o>&lt;</span><span class=k>table_name</span><span class=o>&gt;</span><span class=p>;</span>
</span></code></pre></div> <p>If not all partitions are included in the result, it may indicate a watermark issue with those partitions. We need to ensure that events are sent across all partitions. To test a statement, we can configure it to avoid being an unbounded query by consuming until the latest offset. This can be done by setting: <code>SET 'sql.tables.scan.bounded.mode' = 'latest-offset';</code></p> <p>Flink statement consumes data up to the most recent available offset at the job submission moment. Upon reaching this time, Flink ensures that a final watermark is propagated, indicating that all results are complete and ready for reporting. The statement then transitions into a 'COMPLETED' state."</p> <p>The table alteration can be undone with:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=k>ALTER</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=o>&lt;</span><span class=k>table_name</span><span class=o>&gt;</span><span class=w> </span><span class=k>DROP</span><span class=w> </span><span class=n>_part</span><span class=p>;</span>
</span></code></pre></div> <h2 id=data-skew>Data Skew<a class=headerlink href=#data-skew title="Permanent link">&para;</a></h2> <p><em>This section assumes a lot of knowledge on sql, joins, stateful state. It is in the concept chapter because I am not sure where to put it otherwise</em>.</p> <p>When dealing with large scale dataset and state, keys used for upsert operation, joins or aggregrations may be subject to data skew. Hot keys are sent to the same Flink subtask. Those operator workers receive most of the records while others are idle. Scaling the number of task manager will not help, as the majority of records go to the same task. </p> <p>It is important to compute the number of keys found in left and right tables. NULL key may be found, and may be also very common. </p> <p>The following query is a standard approach to assess the percent allocation of all the data groups:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=k>SELECT</span><span class=w> </span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=w>    </span><span class=k>column_name</span><span class=p>,</span><span class=w> </span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=w>    </span><span class=k>COUNT</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>rows_count</span><span class=p>,</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=k>FROM</span><span class=w> </span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=w>    </span><span class=n>your_table_name</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=k>GROUP</span><span class=w> </span><span class=k>BY</span><span class=w> </span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=w>    </span><span class=k>column_name</span><span class=p>;</span>
</span></code></pre></div> <p>If for example one value accounts for more than 30% of the rows then we face data skew.</p> <p>For join, Flink distributes rows based on key used in the on condition.</p> <p>It is then necessary to use a 'salting' key technique, by spreading the hot key to multiple processing tasks. The original join looks like:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>select</span><span class=w> </span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=w>    </span><span class=n>u</span><span class=p>.</span><span class=o>*</span><span class=p>,</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=w>    </span><span class=k>g</span><span class=p>.</span><span class=n>group_name</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=k>from</span><span class=w> </span><span class=n>src_users</span><span class=w> </span><span class=n>u</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=k>join</span><span class=w> </span><span class=n>src_groups</span><span class=w> </span><span class=k>g</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>u</span><span class=p>.</span><span class=n>group_id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>g</span><span class=p>.</span><span class=n>id</span>
</span></code></pre></div> <p>For that we need to add a column (the salt) to the skewed table and the smaller tllbe, and append a sequence number between 0 to N-1, where N is the number of buckets to use to repartition the data. See <a href=https://github.com/jbcodeforce/flink-udfs-catalog/tree/main/sequence>SEQUENCE UDTF</a></p> <p>Below is an example to create 3 buckets for each key of the slow table:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1>-- using the SEQUENCE UDF</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=k>create</span><span class=w> </span><span class=k>view</span><span class=w> </span><span class=n>groups_salted</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=k>select</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=w>   </span><span class=k>g</span><span class=p>.</span><span class=o>*</span><span class=p>,</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=w>  </span><span class=n>S</span><span class=p>.</span><span class=n>salt_id</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>salt_id</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=k>from</span><span class=w> </span><span class=o>`</span><span class=n>src_groups</span><span class=o>`</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=k>g</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=k>cross</span><span class=w> </span><span class=k>join</span><span class=w> </span><span class=k>lateral</span><span class=w> </span><span class=k>table</span><span class=p>(</span><span class=n>SEQUENCE</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>S</span><span class=p>(</span><span class=n>salt_id</span><span class=p>)</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=c1>-- using the UNNEST</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=k>CROSS</span><span class=w> </span><span class=k>JOIN</span><span class=w> </span><span class=k>UNNEST</span><span class=p>(</span><span class=nb>ARRAY</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=w> </span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>,</span><span class=w> </span><span class=mi>3</span><span class=p>,</span><span class=w> </span><span class=mi>4</span><span class=p>,</span><span class=w> </span><span class=mi>5</span><span class=p>,</span><span class=w> </span><span class=mi>6</span><span class=p>,</span><span class=w> </span><span class=mi>7</span><span class=p>,</span><span class=w> </span><span class=mi>8</span><span class=p>,</span><span class=w> </span><span class=mi>9</span><span class=p>])</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>S</span><span class=p>(</span><span class=n>salt_id</span><span class=p>)</span>
</span></code></pre></div> <p>Same approach applies to the big table, if we can do it with a view <div class="language-sql highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=k>create</span><span class=w> </span><span class=k>view</span><span class=w> </span><span class=n>users_salted</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=k>select</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=w>  </span><span class=n>u</span><span class=p>.</span><span class=o>*</span><span class=p>,</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=w>  </span><span class=n>S</span><span class=p>.</span><span class=n>salt_id</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>salt_id</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=k>from</span><span class=w> </span><span class=o>`</span><span class=n>src_users</span><span class=o>`</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>u</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=k>cross</span><span class=w> </span><span class=k>join</span><span class=w> </span><span class=k>lateral</span><span class=w> </span><span class=k>table</span><span class=p>(</span><span class=n>SEQUENCE</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>S</span><span class=p>(</span><span class=n>salt_id</span><span class=p>)</span>
</span></code></pre></div></p> <p>The joins now taking into account the combined key: <div class="language-sql highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=k>select</span><span class=w> </span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=w>    </span><span class=n>u</span><span class=p>.</span><span class=o>*</span><span class=p>,</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=w>    </span><span class=k>g</span><span class=p>.</span><span class=n>group_name</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=k>from</span><span class=w> </span><span class=n>users_salted</span><span class=w> </span><span class=n>u</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a><span class=k>join</span><span class=w> </span><span class=n>groups_salted</span><span class=w> </span><span class=k>g</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>u</span><span class=p>.</span><span class=n>group_id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>g</span><span class=p>.</span><span class=n>id</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>u</span><span class=p>.</span><span class=n>salt_id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>g</span><span class=p>.</span><span class=n>salt_id</span>
</span></code></pre></div></p> <p>When the join needs to be temporal, we may need tables and not a view.</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a>
</span></code></pre></div> <p>To demonstrate the partitioning, use a sink topic with 3 partitions, and a partition key based on group_id with the first approach a lot of records are going one partition, while with the salty key, the sink partition key will be group_id and salt_id and so will be spread against the 3 partitions.</p> <p><a href=https://github.com/jbcodeforce/flink-studies/tree/master/code/flink-sql/04-joins/data_skew>See matching demo scripts in flink-sql/04-joins/data_skew.</a></p> <h2 id=from-batch-to-real-time>From batch to real-time<a class=headerlink href=#from-batch-to-real-time title="Permanent link">&para;</a></h2> <p>In business analytics there is a need to differentiate data tables according to their usage and reusability. There are two important concepts of this practice:</p> <ul> <li>The <strong>Dimensions</strong>, which provide the who, what, where, when, why, and how context surrounding a business process event. Dimension tables contain the descriptive attributes used by BI applications for ltering and grouping the facts. </li> <li>The <strong>Facts</strong>, which are the measurements that result from a business process event and are almost always numeric. The design of a fact table is entirely based on a physical activity, and not by the reports to produce from those facts. A fact table always contains foreign keys for each of its associated dimensions, as well as optional degenerate dimension keys and date/time stamps.</li> </ul> <h3 id=the-star-schema>The star schema<a class=headerlink href=#the-star-schema title="Permanent link">&para;</a></h3> <p>The star schema, was defined at the end of the 80s, as a multi-dimensional data model to organize data in Date warehouse, to maintain history and by reducing the data duplication. A star schema is used to denormalize business data into dimensions and facts. The fact table connects to multiple other dimension tables along "dimensions" like time, or product.</p> <p><img alt src=diagrams/star_schema.drawio.png></p> <p>The following project illustrates how to implement the star schema using Flink:</p> <ul> <li><a href=https://jbcodeforce.github.io/flink_project_demos/c360/flink_project/#define-the-shift_left-utils-configuration>Customer 360</a></li> <li><a href=https://github.com/jbcodeforce/flink_project_demos/tree/main/tx_processing>Transaction analytics</a></li> </ul> <p>In Flink a dimension may created via a SQL statement, and persisted as table with Kafka topic, JDBC table or files. When less reusable a Dimension can be a CTE within a bigger flink statement.</p> <details class=info open=open> <summary>How to support Type 2 slowly changing dimension (SCD) table?</summary> <p>Type 2 SCDs are designed to maintain a complete history of all changes to dimension data. When a change occurs, a new row is inserted into the table, representing the updated record, while the original record remains untouched. Each record in the table is typically assigned a unique identifier (often a surrogate key) to distinguish between different versions of the same dimension member. </p> </details> <h2 id=source-of-knowledge>Source of knowledge<a class=headerlink href=#source-of-knowledge title="Permanent link">&para;</a></h2> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://flink.apache.org/flink-architecture.html>Apache Flink Product documentation</a>. </li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/learn-flink/ >Official Apache Flink training</a>.</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://developer.confluent.io/courses/apache-flink/intro/ >Confluent "Fundamentals of Apache Flink" training- David Anderson</a>.</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/concepts/flink-architecture/#anatomy-of-a-flink-cluster>Anatomy of a Flink Cluster - product documentation.</a></li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/internals/job_scheduling/ >Jobs and Scheduling - Flink product documentation.</a></li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://docs.confluent.io/cloud/current/flink/overview.html>Confluent Cloud Flink product documentation</a></li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://docs.confluent.io/platform/current/flink/overview.html>Confluent Plaform for Flink product documentation</a></li> <li>Base docker image is: <a href=https://hub.docker.com/_/flink>https://hub.docker.com/_/flink</a></li> <li><a href=https://ci.apache.org/projects/flink/flink-docs-master/ops/deployment/docker.html>Flink docker setup</a> and the docker-compose files in this repo.</li> <li><a href=https://wints.github.io/flink-web/faq.html>FAQ</a></li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <a href=https://github.com/cloudera/flink-tutorials/tree/master/flink-stateful-tutorial>Cloudera flink stateful tutorial</a>: very good example for inventory transaction and queries on item considered as stream</li> <li><a href=https://www.elastic.co/blog/building-real-time-dashboard-applications-with-apache-flink-elasticsearch-and-kibana>Building real-time dashboard applications with Apache Flink, Elasticsearch, and Kibana</a></li> </ul> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=.. class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Introduction </div> </div> </a> <a href=../coding/getting-started/ class="md-footer__link md-footer__link--next" aria-label="Next: Getting started"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Getting started </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2026 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "..", "features": ["content.code.annotation", "content.code.copy", "content.tooltips", "content.tabs.link", "search.suggest", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.79ae519e.min.js></script> </body> </html>