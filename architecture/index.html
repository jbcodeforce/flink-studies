<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/flink-studies/architecture/ rel=canonical><link href=../coding/getting-started/ rel=prev><link href=fitforpurpose/ rel=next><link rel=icon href=../images/logo-blue.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.22"><title>Flink Architecture - Apache and Confluent Flink Studies</title><link rel=stylesheet href=../assets/stylesheets/main.84d31ad4.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../assets/_mkdocstrings.css><link rel=stylesheet href=../extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#flink-architecture class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Apache and Confluent Flink Studies" class="md-header__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../images/flink-header-logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Apache and Confluent Flink Studies </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Flink Architecture </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class="md-tabs__item md-tabs__item--active"> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=flink-sql/ class=md-tabs__link> Recipes </a> </li> <li class=md-tabs__item> <a href=../methodology/data_as_a_product/ class=md-tabs__link> Methodology </a> </li> <li class=md-tabs__item> <a href=../techno/ccloud-flink/ class=md-tabs__link> Related Technologies </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-tabs__link> EDA </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Apache and Confluent Flink Studies" class="md-nav__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../images/flink-header-logo.svg alt=logo> </a> Apache and Confluent Flink Studies </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1 checked> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex> <span class=md-ellipsis> Home </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=true> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../concepts/ class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=../coding/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Flink Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Flink Architecture </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#runtime-architecture class=md-nav__link> <span class=md-ellipsis> Runtime architecture </span> </a> </li> <li class=md-nav__item> <a href=#batch-processing class=md-nav__link> <span class=md-ellipsis> Batch processing </span> </a> </li> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State management </span> </a> </li> <li class=md-nav__item> <a href=#high-availability class=md-nav__link> <span class=md-ellipsis> High Availability </span> </a> </li> <li class=md-nav__item> <a href=#fault-tolerance class=md-nav__link> <span class=md-ellipsis> Fault Tolerance </span> </a> <nav class=md-nav aria-label="Fault Tolerance"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#checkpointing class=md-nav__link> <span class=md-ellipsis> Checkpointing </span> </a> </li> <li class=md-nav__item> <a href=#savepoints class=md-nav__link> <span class=md-ellipsis> Savepoints </span> </a> </li> <li class=md-nav__item> <a href=#faqs class=md-nav__link> <span class=md-ellipsis> FAQs </span> </a> </li> <li class=md-nav__item> <a href=#checkpoints-impact-throughput class=md-nav__link> <span class=md-ellipsis> Checkpoints impact throughput </span> </a> </li> <li class=md-nav__item> <a href=#interuption-while-writing-checkpoints class=md-nav__link> <span class=md-ellipsis> Interuption while writing checkpoints </span> </a> </li> <li class=md-nav__item> <a href=#when-flink-cluster-has-10-nodes-what-happen-in-one-node-failure class=md-nav__link> <span class=md-ellipsis> When Flink cluster has 10 nodes what happen in one node failure </span> </a> </li> <li class=md-nav__item> <a href=#can-we-set-one-task-manager-one-task-to-run-all-a-dag-to-make-it-simple class=md-nav__link> <span class=md-ellipsis> Can we set one task manager one task to run all a DAG to make it simple? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#network-stack class=md-nav__link> <span class=md-ellipsis> Network Stack </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=fitforpurpose/ class=md-nav__link> <span class=md-ellipsis> Fit for purpose </span> </a> </li> <li class=md-nav__item> <a href=../labs/ class=md-nav__link> <span class=md-ellipsis> Labs-Demos </span> </a> </li> <li class=md-nav__item> <a href=agentic_flink/ class=md-nav__link> <span class=md-ellipsis> Agentic applications </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Recipes </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Recipes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL concepts </span> </a> </li> <li class=md-nav__item> <a href=../coding/flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL coding </span> </a> </li> <li class=md-nav__item> <a href=../coding/firstapp/ class=md-nav__link> <span class=md-ellipsis> First Java Apps </span> </a> </li> <li class=md-nav__item> <a href=../coding/udf_sql/ class=md-nav__link> <span class=md-ellipsis> UDFs for SQL </span> </a> </li> <li class=md-nav__item> <a href=../coding/k8s-deploy/ class=md-nav__link> <span class=md-ellipsis> Kubernetes Deployment </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Manage CC Flink projects </span> </a> </li> <li class=md-nav__item> <a href=../coding/datastream/ class=md-nav__link> <span class=md-ellipsis> DataStreams </span> </a> </li> <li class=md-nav__item> <a href=cookbook/ class=md-nav__link> <span class=md-ellipsis> Flink Cookbook </span> </a> </li> <li class=md-nav__item> <a href=../coding/table-api/ class=md-nav__link> <span class=md-ellipsis> Table API </span> </a> </li> <li class=md-nav__item> <a href=../coding/stateful-func/ class=md-nav__link> <span class=md-ellipsis> Stateful function </span> </a> </li> <li class=md-nav__item> <a href=../coding/cep/ class=md-nav__link> <span class=md-ellipsis> Complex Event Processing </span> </a> </li> <li class=md-nav__item> <a href=../coding/terraform/ class=md-nav__link> <span class=md-ellipsis> IaC wt Terraform </span> </a> </li> <li class=md-nav__item> <a href=../techno/fk-k8s-monitor/ class=md-nav__link> <span class=md-ellipsis> Flink on k8s Monitoring </span> </a> </li> <li class=md-nav__item> <a href=../labs/ class=md-nav__link> <span class=md-ellipsis> Labs-Demos </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../methodology/data_as_a_product/ class=md-nav__link> <span class=md-ellipsis> Data as a product </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies/methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Migrate to real-time processing tools </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/flink_project_demos/c360/spark_project/ class=md-nav__link> <span class=md-ellipsis> A C360 data product demo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Related Technologies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Related Technologies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../techno/ccloud-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Flink </span> </a> </li> <li class=md-nav__item> <a href=../techno/cp-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Platform for Flink </span> </a> </li> <li class=md-nav__item> <a href=kafka/ class=md-nav__link> <span class=md-ellipsis> Kafka Integration </span> </a> </li> <li class=md-nav__item> <a href=../techno/cc-tableflow/ class=md-nav__link> <span class=md-ellipsis> Confluent TableFlow </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/techno/data/#data-related-technologies class=md-nav__link> <span class=md-ellipsis> Apache Iceberg </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/kafka-studies class=md-nav__link> <span class=md-ellipsis> Kafka-studies </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-nav__link> <span class=md-ellipsis> EDA </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#runtime-architecture class=md-nav__link> <span class=md-ellipsis> Runtime architecture </span> </a> </li> <li class=md-nav__item> <a href=#batch-processing class=md-nav__link> <span class=md-ellipsis> Batch processing </span> </a> </li> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State management </span> </a> </li> <li class=md-nav__item> <a href=#high-availability class=md-nav__link> <span class=md-ellipsis> High Availability </span> </a> </li> <li class=md-nav__item> <a href=#fault-tolerance class=md-nav__link> <span class=md-ellipsis> Fault Tolerance </span> </a> <nav class=md-nav aria-label="Fault Tolerance"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#checkpointing class=md-nav__link> <span class=md-ellipsis> Checkpointing </span> </a> </li> <li class=md-nav__item> <a href=#savepoints class=md-nav__link> <span class=md-ellipsis> Savepoints </span> </a> </li> <li class=md-nav__item> <a href=#faqs class=md-nav__link> <span class=md-ellipsis> FAQs </span> </a> </li> <li class=md-nav__item> <a href=#checkpoints-impact-throughput class=md-nav__link> <span class=md-ellipsis> Checkpoints impact throughput </span> </a> </li> <li class=md-nav__item> <a href=#interuption-while-writing-checkpoints class=md-nav__link> <span class=md-ellipsis> Interuption while writing checkpoints </span> </a> </li> <li class=md-nav__item> <a href=#when-flink-cluster-has-10-nodes-what-happen-in-one-node-failure class=md-nav__link> <span class=md-ellipsis> When Flink cluster has 10 nodes what happen in one node failure </span> </a> </li> <li class=md-nav__item> <a href=#can-we-set-one-task-manager-one-task-to-run-all-a-dag-to-make-it-simple class=md-nav__link> <span class=md-ellipsis> Can we set one task manager one task to run all a DAG to make it simple? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#network-stack class=md-nav__link> <span class=md-ellipsis> Network Stack </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=flink-architecture>Flink architecture<a class=headerlink href=#flink-architecture title="Permanent link">&para;</a></h1> <details class="- info"> <summary>Update</summary> <ul> <li>Created 2018 </li> <li>Updated 11/2024 - review done.</li> <li>12/2024: move fault tolerance in this chapter</li> </ul> </details> <h2 id=runtime-architecture>Runtime architecture<a class=headerlink href=#runtime-architecture title="Permanent link">&para;</a></h2> <p>Flink consists of a <strong>Job Manager</strong> and <code>n</code> <strong>Task Managers</strong> deployed on <code>k</code> hosts. </p> <figure> <img alt=1 src=https://ci.apache.org/projects/flink/flink-docs-release-1.20/fig/distributed-runtime.svg> <figcaption>Main Flink Components</figcaption> </figure> <p>The <strong>JobManager</strong> controls the execution of a single application. Developers submit their application (jar file or SQL statements) via CLI, or k8s manifest. Job Manager receives the Flink application for execution and builds a Task Execution Graph from the defined <strong>JobGraph</strong>. It manages job submission which parallelizes the job and distributes slices of <a href=https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html>the Data Stream</a> flow, the developers have defined. Each parallel slice of the job is a task that is executed in a <strong>task slot</strong>. </p> <p>Once the job is submitted, the <strong>Job Manager</strong> is scheduling the job to different task slots within the <strong>Task Manager</strong>. The Job manager may create resources from a computer pool, or when deployed on kubernetes, it creates pods. </p> <p>The <strong>Resource Manager</strong> manages Task Slots and leverages an underlying orchestrator, like Kubernetes or Yarn (deprecated).</p> <p>A <strong>Task slot</strong> is the unit of work executed on CPU. The <strong>Task Managers</strong> execute the actual stream processing logic. There are multiple task managers running in a cluster. The number of slots limits the number of tasks a TaskManager can execute. After it has been started, a TaskManager registers its slots to the ResourceManager:</p> <figure> <img alt=2 src=images/flink-components.png> <figcaption>Sequence flow from job submission</figcaption> </figure> <p>The <strong>Dispatcher</strong> exposes API to submit applications for execution. It hosts the user interface too.</p> <p>Once the job is running, the Job Manager is responsible to coordinate the activities of the Flink cluster, like checkpointing, and restarting task manager that may have failed.</p> <p>Tasks are loading the data from sources, do their own processing and then send data among themselves for repartitioning and rebalancing, to finally push results out to the sinks.</p> <p>When Flink is not able to process a real-time event, it may have to buffer it, until other necessary data has arrived. This buffer has to be persisted in longer storage, so data are not lost if a task manager fails and has to be restarted. In batch mode, the job can reload the data from the beginning. In batch the results are computed once the job is done (count the number of record like <code>select count(*) AS</code>count<code>from bounded_pageviews;</code> return one result), while in streaming mode, each event may be the last one received, so results are produced incrementally, after every events or after a certain period of time based on timers.</p> <details class=-> <summary>Parameters</summary> <ul> <li>taskmanager.numberOfTaskSlots: 2</li> </ul> </details> <p>Once Flink is started (for example with the docker image), Flink Dashboard <a href=http://localhost:8081/#/overview>http://localhost:8081/#/overview</a> presents the execution reporting:</p> <figure> <img alt=3 src=images/flink-dashboard.png> <figcaption>Flink User Interface</figcaption> </figure> <p>The execution is from one of the training examples, the number of task slot was set to 4, and one job is running.</p> <p>Spark Streaming is using microbatching which is not a true real-time processing while Flink is a RT engine. Both Flink and Spark support batch processing. </p> <p>Only one Job Manager is active at a given point of time, and there may be <code>n</code> Task Managers. It is a single point of failure, but it startes quickly and can leverage the checkpoints data to restart its processing.</p> <p>There are different <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.20/ops/deployment/ >deployment models</a>: </p> <ul> <li>Deploy on executing cluster, this is the <strong>session mode</strong>. Use <strong>session</strong> cluster to run multiple jobs: we need a separate JobManager container for that. </li> <li><strong>Per job</strong> mode: spin up a cluster per job submission. This provides better resource isolation. </li> <li><strong>Application mode</strong>: creates a cluster per app with the <code>main()</code> function executed on the JobManager. It can include multiple jobs but they run inside the app. It allows for saving the required CPU cycles, but also save the bandwidth required for downloading the dependencies locally.</li> </ul> <p>Flink can run on any common resource manager like Hadoop Yarn, Mesos, or Kubernetes. For development purpose, we can use docker images to deploy a <strong>Session</strong> or <strong>Job cluster</strong>.</p> <p>See also <a href=../coding/k8s-deploy/ >deployment to Kubernetes</a></p> <p>The new K8s operator, deploys and monitors Flink Application and Session deployments.</p> <h2 id=batch-processing>Batch processing<a class=headerlink href=#batch-processing title="Permanent link">&para;</a></h2> <p>Process all the data in one job with bounded dataset. It is used when we need all the data, to assess trend, develop AI model, and with a focus on throughput instead of latency. Jobs are run when needed, on input that can be pre-sorted by time or by any other key.</p> <p>The results are reported at the end of the job execution. Any failure means to do of full restart of the job.</p> <p>Hadoop was designed to do batch processing. Flink has capability to replace the Hadoop map-reduce processing.</p> <p>When latency is a major requirements, like monitoring and alerting, fraud detection then streaming is the only choice.</p> <h2 id=state-management>State management<a class=headerlink href=#state-management title="Permanent link">&para;</a></h2> <p><a href=https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/state/ >See 'working with state' from Flink documentation</a>.</p> <ul> <li> <p>All data maintained by a task and used to compute the results of a function belong to the state of the task. Function may use <k,v> pairs to store values, and may implement The ChekpointedFunctions to make local state fault tolerant.</p> </li> <li> <p>While processing the data, the task can read and update its state and computes its results based on its input data and state.</p> </li> <li>State management may address very large states, and no state is lost in case of failures.</li> <li>Within a DAG, each operator needs to register its state.</li> <li><strong>Operator state</strong> is scoped to an operator task: all records processed by the same parallel task have access to the same state.</li> <li><strong>Keyed state</strong> is maintained and accessed with respect to a key defined in the records of an operator’s input stream. Flink maintains one state instance per key value and Flink partitions all records with the same key to the operator task that maintains the state for this key. The key-value map is sharded across all parallel tasks:</li> </ul> <figure> <img alt src=images/key-state.png width=600> <figcaption>Keyes states</figcaption> </figure> <ul> <li>Each task maintains its state locally to improve latency. For small state, the state backends will use JVM heap, but for larger state RocksDB is used. A <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/state_backends/ ><strong>state backend</strong></a> takes care of checkpointing the state of a task to a remote and persistent storage.</li> <li>With stateful distributed processing, scaling stateful operators, enforces state repartitioning and assigning to more or fewer parallel tasks. Keys are organized in key-groups, and key groups are assigned to tasks. Operators with operator list state are scaled by redistributing the list entries. Operators with operator union list state are scaled by broadcasting the full list of state entries to each task.</li> </ul> <details class="- info"> <summary>State Backend</summary> <ul> <li>Embedded rockdb will persist on Task manager local data directories. It saves asynchronously. Serializes using bytes. But there is a limit to the size per key and valye of 2^31 bytes. Supports incremental checkpoints</li> <li>ForStState use tree structured k-v store. May use object storage for remote file systems. Allows Flink to scale the state size beyond the local disk capacity of the TaskManager. </li> <li><code>HashMapStateBackend</code> use Java heap to keep state, as java object. So unsafe to reuse!.</li> </ul> </details> <h2 id=high-availability>High Availability<a class=headerlink href=#high-availability title="Permanent link">&para;</a></h2> <p>With Task managers running in parallel, if one fails the number of available slots drops, and the JobManager asks the Resource Manager to get new processing slots. The application's restart strategy determines how often the JobManager restarts the application and how long it waits between restarts.</p> <p>Flink OSS uses Zookeeper to manage multiple JobManagers and select the leader to control the execution of the streaming jobs. Application's tasks checkpoints and other states are saved in a remote storage, but metadata are saved in Zookeeper. When a JobManager fails, all tasks that belong to its application are automatically cancelled. A new JobManager that takes over the work by getting information of the storage from Zookeeper, and then restarts the process with the JobManager.</p> <h2 id=fault-tolerance>Fault Tolerance<a class=headerlink href=#fault-tolerance title="Permanent link">&para;</a></h2> <p>The two major Flink features to support fault tolerance are the checkpoints and savepoints. </p> <h3 id=checkpointing>Checkpointing<a class=headerlink href=#checkpointing title="Permanent link">&para;</a></h3> <p><a href=https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/ops/state/checkpoints/ >Checkpoints</a> are snapshots of the input data stream, capturing the state of each operator, of the DAG, at a specific point in time. They are created automatically and periodically by Flink. The saved states are used to recover from failures, and checkpoints are optimized for quick recovery.</p> <p><strong>Checkpoints</strong> allow a streaming dataflow to be resumed from a checkpoint while maintaining consistency through exactly-once processing semantics. When a failure occurs, Flink can restore the state of the operators and replay the records starting from the checkpoint.</p> <p>In the event of a failure in a parallel execution, Flink halts the stream flow and restarts the operators from the most recent checkpoints. During data partition reallocation for processing, the associated states are also reallocated. States are stored in distributed file systems, and when Kafka is used as the data source, the committed read offsets are included in the checkpoint data.</p> <p>Checkpointing is coordinated by the Job Manager, it knows the location of the latest completed checkpoint which will get important later on. This checkpointing and recovery mechanism can provide exactly-once consistency for application state, given that all operators checkpoint and restore all of their states and that all input streams are reset to the position up to which they were consumed when the checkpoint was taken. This will work perfectly with Kafka, but not with sockets or queues where messages are lost once consumed. Therefore exactly-once state consistency can be ensured only if all input streams are from reset-able data sources.</p> <p>As part of the checkpointing process, Flink saves the 'offset read commit' information of the append log, so in case of a failure, Flink recovers the stateful streaming application by restoring its state from a previous checkpoint and resetting the read position on the append log.</p> <p>During the recovery and depending on the sink operators of an application, some result records might be emitted multiple times to downstream systems. Downstream systems need to be idempotent.</p> <p>Flink utilizes the concept of <strong>Checkpoint Barriers</strong> to delineate records. These barriers separate records so that those received after the last snapshot are included in the next checkpoint, ensuring a clear and consistent state transition.</p> <p>Barrier can be seen as a mark, a tag, in the data stream and aims to close a snapshot. </p> <figure> <img alt=Checkpoints src=images/checkpoints.png width=600> <figcaption>Checkpointing concepts</figcaption> </figure> <p>Checkpoint barriers flow with the stream, allowing them to be distributed across the system. When a sink operator — located at the end of a streaming Directed Acyclic Graph (DAG) — receives <code>barrier n</code> from all its input streams, it acknowledges <code>snapshot n</code> to the checkpoint coordinator.</p> <p>Once all sink operators have acknowledged a snapshot, it is considered completed. After <code>snapshot n</code> is finalized, the job will not request any records from the source prior to that snapshot, ensuring data consistency and integrity.</p> <p>State snapshots are stored in a <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/state_backends/ >state backend</a>, which can include options such as in-memory storage, HDFS, object storage or RocksDB. This flexibility allows for optimal performance and scalability based on the application’s requirements.</p> <p>In the context of a KeyedStream, Flink functions as a key-value store where the key corresponds to the key in the stream. State updates do not require transactions, simplifying the update process.</p> <p>For DataSet (Batch processing) there is no checkpoint, so in case of failure the stream is replayed from the beginning.</p> <p>When addressing exactly once processing, it is crucial to consider the following steps:</p> <ul> <li><strong>Read Operation from the Source</strong>: Ensuring that the data is read exactly once is foundational. Flink's source connectors are designed to handle this reliably through mechanisms like checkpointing.</li> <li><strong>Apply Processing Logic</strong> which involves operations such as window aggregation or other transformations, which can also be executed with exactly-once semantics when properly configured.</li> <li><strong>Generate Results to a Sink</strong> introduces more complexity. While reading from the source and applying processing logic can be managed to ensure exactly-once semantics, generating a unique result to a sink depends on the target technology and its capabilities. Different sink technologies may have varying levels of support for exactly-once processing, requiring additional strategies such as idempotent writes or transactional sinks to achieve the desired consistency.</li> </ul> <figure> <img alt src=images/e2e-1.png width=800> <figcaption>End-to-end exactly once</figcaption> </figure> <p>After reading records from Kafka, processing them, and generating results, if a failure occurs, Flink will revert to the last committed read offset. This means it will reload the records from Kafka and reprocess them. As a result, this can lead to duplicate entries being generated in the sink:</p> <figure> <img alt src=images/e2e-2.png width=800> <figcaption>End-to-end recovery</figcaption> </figure> <p>Since duplicates may occur, it is crucial to assess how downstream applications handle idempotence. Many distributed key-value stores are designed to provide consistent results even after retries, which can help manage duplicate entries effectively.</p> <p>To achieve end-to-end exactly-once delivery, it is essential to utilize a sink that supports transactions and implements a two-phase commit protocol. In the event of a failure, this allows for the rollback of any output generated, ensuring that only successfully processed data is committed. However, it's important to note that implementing transactional outputs can impact overall latency.</p> <p>Flink takes checkpoints periodically — typically every 10 seconds — which establishes the minimum latency we can expect at the sink level. This periodic checkpointing is a critical aspect of maintaining state consistency while balancing the need for timely data processing.</p> <p>For Kafka Sink connector, as kafka producer, we need to set the <code>transactionId</code>, and the delivery guarantee type:</p> <div class="language-java highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>new</span><span class=w> </span><span class=n>KafkaSinkBuilder</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span><span class=p>()</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=w>    </span><span class=p>.</span><span class=na>setBootstrapServers</span><span class=p>(</span><span class=n>bootstrapURL</span><span class=p>)</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=w>    </span><span class=p>.</span><span class=na>setDeliverGuarantee</span><span class=p>(</span><span class=n>DeliveryGuarantee</span><span class=p>.</span><span class=na>EXACTLY_ONCE</span><span class=p>)</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=w>    </span><span class=p>.</span><span class=na>setTransactionalIdPrefix</span><span class=p>(</span><span class=s>&quot;store-sol&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>With transaction ID, a sequence number is sent by the Kafka producer API to the broker, and so the partition leader will be able to remove duplicate retries.</p> <figure> <img alt src=images/e2e-3.png width=800> <figcaption>End-to-end with Kafka transaction id</figcaption> </figure> <p>When the checkpointing period is set, we need to also configure <code>transaction.max.timeout.ms</code> of the Kafka broker and <code>transaction.timeout.ms</code> for the producer (sink connector) to a higher timeout than the checkpointing interval plus the max expected Flink downtime. If not the Kafka broker will consider the connection has failed and will remove its state management.</p> <p>The evolution of microservice is to become more event-driven, which are stateful streaming applications that ingest event streams and process the events with application-specific business logic. This logic can be done in flow defined in Flink and executed in the clustered runtime.</p> <figure> <img alt src=images/evt-app.png> <figcaption>Event-driven application as a sequence of Flink apps</figcaption> </figure> <p>State is always accessed locally, which helps Flink applications achieve high throughput and low-latency. Developers can choose to keep state on the JVM heap, or if it is too large, save it on-disk.</p> <figure> <img alt=4 src=https://ci.apache.org/projects/flink/flink-docs-release-1.19/fig/local-state.png> <figcaption>Different State Storage</figcaption> </figure> <h3 id=savepoints>Savepoints<a class=headerlink href=#savepoints title="Permanent link">&para;</a></h3> <p>Savepoints are user triggered snapshot at a specific point in time. It is used during system operations like product upgrades. The Flink operator for kubernetes has <a href=../coding/k8s-deploy/#ha-configuration>custom resource definition</a> to support the savepoint process. See also the end to end demo for savepoint in <a href=https://github.com/jbcodeforce/flink-studies/blob/master/e2e-demos/savepoint-demo>this folder.</a></p> <h3 id=faqs>FAQs<a class=headerlink href=#faqs title="Permanent link">&para;</a></h3> <h3 id=checkpoints-impact-throughput>Checkpoints impact throughput<a class=headerlink href=#checkpoints-impact-throughput title="Permanent link">&para;</a></h3> <ul> <li>The persistence to remote storage is done asynchronously, but at the level of a task. So too frequent checkpointing will impact throughput. Now it also depends if the tasks are compute or IO intensive. </li> </ul> <h3 id=interuption-while-writing-checkpoints>Interuption while writing checkpoints<a class=headerlink href=#interuption-while-writing-checkpoints title="Permanent link">&para;</a></h3> <ul> <li>The processing will restart from the last persisted checkpoints so no data loss. Specially true when source of the data are coming from Kafka topics. The checkpoint points to last read-commited offset within topic/partition so Flink will reload from there</li> </ul> <h3 id=when-flink-cluster-has-10-nodes-what-happen-in-one-node-failure>When Flink cluster has 10 nodes what happen in one node failure<a class=headerlink href=#when-flink-cluster-has-10-nodes-what-happen-in-one-node-failure title="Permanent link">&para;</a></h3> <p>It will depend of the operator allocation to the task to the task manager and what the operator needs (as state). At worse case the full DAG needs to be restored, every operator needs to rebuild their state so multiple task managers in the cluster.</p> <p>It can take sometime to recover. Reread data and reprocess it, will take many seconds, or minutes. </p> <p>With hot-hot deployment, it is possible to get the same running application running in parallel, and then switch the output sink / topic for the consumer. For real-time payment we can achieve around 3 to 7 seconds recovery time, with million of records per second. </p> <h3 id=can-we-set-one-task-manager-one-task-to-run-all-a-dag-to-make-it-simple>Can we set one task manager one task to run all a DAG to make it simple?<a class=headerlink href=#can-we-set-one-task-manager-one-task-to-run-all-a-dag-to-make-it-simple title="Permanent link">&para;</a></h3> <p>It will depend of the application state size and logic to operate. If all state stays in memory, yes this is a common pattern to use. If state are bigger than physical memory of the computer running the task manager, then the processing needs more computers, so more task managers and need to distribute data. Then it needs distributed storage to persist states. </p> <h2 id=network-stack>Network Stack<a class=headerlink href=#network-stack title="Permanent link">&para;</a></h2> <p>The Flink network stack helps connecting work units across TaskManagers using Netty. Flink uses a credit-based flow control for managing buffer availability and preventing backpressure.</p> <p>See the <a href=https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/ >Deep dive article in Flink network stack</a></p> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../coding/getting-started/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Getting started"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Getting started </div> </div> </a> <a href=fitforpurpose/ class="md-footer__link md-footer__link--next" aria-label="Next: Fit for purpose"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Fit for purpose </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2025 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "..", "features": ["content.code.annotation", "content.code.copy", "content.tooltips", "content.tabs.link", "search.suggest", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.f55a23d4.min.js></script> </body> </html>