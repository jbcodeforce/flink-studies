<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/flink-studies/techno/ccloud-flink/ rel=canonical><link href=../../methodology/coe/ rel=prev><link href=../cp-flink/ rel=next><link rel=icon href=../../images/logo-blue.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.2"><title>Confluent Cloud Flink - Apache and Confluent Flink Studies</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#confluent-cloud-for-apache-flink class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Apache and Confluent Flink Studies" class="md-header__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../../images/flink-header-logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Apache and Confluent Flink Studies </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Confluent Cloud Flink </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Foundations </a> </li> <li class=md-tabs__item> <a href=../../cookbook/ class=md-tabs__link> Cookbook </a> </li> <li class=md-tabs__item> <a href=../../coding/flink-sql-clients/ class=md-tabs__link> Flink_App_Coding </a> </li> <li class=md-tabs__item> <a href=../../methodology/data_as_a_product/ class=md-tabs__link> Methodology </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Related_Technologies </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-tabs__link> EDA </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Apache and Confluent Flink Studies" class="md-nav__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../../images/flink-header-logo.svg alt=logo> </a> Apache and Confluent Flink Studies </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex=0> <span class=md-ellipsis> Foundations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Foundations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/ class=md-nav__link> <span class=md-ellipsis> Flink Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=../../coding/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL concepts </span> </a> </li> <li class=md-nav__item> <a href=../../labs/ class=md-nav__link> <span class=md-ellipsis> Code&Demos </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/agentic_flink/ class=md-nav__link> <span class=md-ellipsis> Agentic applications </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Cookbook </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Cookbook </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../cookbook/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../cookbook/considerations/ class=md-nav__link> <span class=md-ellipsis> Considerations </span> </a> </li> <li class=md-nav__item> <a href=../../cookbook/cluster_mgt/ class=md-nav__link> <span class=md-ellipsis> Cluster management </span> </a> </li> <li class=md-nav__item> <a href=../../cookbook/job_lifecycle/ class=md-nav__link> <span class=md-ellipsis> Job Lifecycle </span> </a> </li> <li class=md-nav__item> <a href=../../coding/k8s-deploy/ class=md-nav__link> <span class=md-ellipsis> FKO & CMF Deployment </span> </a> </li> <li class=md-nav__item> <a href=../../cookbook/terraform/ class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Terraform </span> </a> </li> <li class=md-nav__item> <a href=../fk-k8s-monitor/ class=md-nav__link> <span class=md-ellipsis> Monitoring </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Flink_App_Coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Flink_App_Coding </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Flink SQL coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Flink SQL coding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../coding/flink-sql-clients/ class=md-nav__link> <span class=md-ellipsis> SQL Clients </span> </a> </li> <li class=md-nav__item> <a href=../../coding/flink-sql-1/ class=md-nav__link> <span class=md-ellipsis> Create Table (SQL) </span> </a> </li> <li class=md-nav__item> <a href=../../coding/flink-sql-2/ class=md-nav__link> <span class=md-ellipsis> SQL DML </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Java - Python </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Java - Python </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../coding/table-api/ class=md-nav__link> <span class=md-ellipsis> Table API </span> </a> </li> <li class=md-nav__item> <a href=../../coding/datastream/ class=md-nav__link> <span class=md-ellipsis> DataStreams API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../coding/udf_sql/ class=md-nav__link> <span class=md-ellipsis> UDFs & PTFs </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Manage CC Flink projects </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_5> <label class=md-nav__link for=__nav_3_5 id=__nav_3_5_label tabindex=0> <span class=md-ellipsis> More advanced topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_5_label aria-expanded=false> <label class=md-nav__title for=__nav_3_5> <span class="md-nav__icon md-icon"></span> More advanced topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../coding/stateful-func/ class=md-nav__link> <span class=md-ellipsis> Stateful function </span> </a> </li> <li class=md-nav__item> <a href=../../coding/cep/ class=md-nav__link> <span class=md-ellipsis> Complex Event Processing </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../methodology/data_as_a_product/ class=md-nav__link> <span class=md-ellipsis> Data as a product </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies/methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Migrate to real-time processing tools </span> </a> </li> <li class=md-nav__item> <a href=../../methodology/coe/ class=md-nav__link> <span class=md-ellipsis> Center of Excellence </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/flink_project_demos/c360/spark_project/ class=md-nav__link> <span class=md-ellipsis> A C360 data product demo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Related_Technologies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Related_Technologies </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Confluent Cloud Flink </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Confluent Cloud Flink </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#comparaison-with-apache-flink class=md-nav__link> <span class=md-ellipsis> Comparaison with Apache Flink </span> </a> </li> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> <nav class=md-nav aria-label="Key Concepts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#confluent-cloud-architecture class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Architecture </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#some-common-commands-to-manage-confluent-cloud-environment class=md-nav__link> <span class=md-ellipsis> Some common commands to manage Confluent Cloud environment </span> </a> </li> <li class=md-nav__item> <a href=#use-the-flink-sql-shell class=md-nav__link> <span class=md-ellipsis> Use the Flink SQL shell </span> </a> </li> <li class=md-nav__item> <a href=#using-the-flink-editor-in-confluent-cloud class=md-nav__link> <span class=md-ellipsis> Using the Flink editor in Confluent Cloud </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#using-the-flink-table-api class=md-nav__link> <span class=md-ellipsis> Using the Flink Table API </span> </a> </li> <li class=md-nav__item> <a href=#dlq-support class=md-nav__link> <span class=md-ellipsis> DLQ support </span> </a> </li> <li class=md-nav__item> <a href=#networking-overview class=md-nav__link> <span class=md-ellipsis> Networking overview </span> </a> </li> <li class=md-nav__item> <a href=#autopilot class=md-nav__link> <span class=md-ellipsis> Autopilot </span> </a> </li> <li class=md-nav__item> <a href=#cross-region-processing class=md-nav__link> <span class=md-ellipsis> Cross-region processing </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-and-troubleshouting class=md-nav__link> <span class=md-ellipsis> Monitoring and troubleshouting </span> </a> <nav class=md-nav aria-label="Monitoring and troubleshouting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#statement-monitoring class=md-nav__link> <span class=md-ellipsis> Statement monitoring </span> </a> </li> <li class=md-nav__item> <a href=#degraded-statement class=md-nav__link> <span class=md-ellipsis> Degraded Statement </span> </a> </li> <li class=md-nav__item> <a href=#query-profiler class=md-nav__link> <span class=md-ellipsis> Query Profiler </span> </a> </li> <li class=md-nav__item> <a href=#metrics class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> </li> <li class=md-nav__item> <a href=#compute-pool-monitoring class=md-nav__link> <span class=md-ellipsis> Compute pool monitoring </span> </a> </li> <li class=md-nav__item> <a href=#some-common-errors class=md-nav__link> <span class=md-ellipsis> Some common errors </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#role-base-access-control class=md-nav__link> <span class=md-ellipsis> Role Base Access Control </span> </a> </li> <li class=md-nav__item> <a href=#understanding-pricing class=md-nav__link> <span class=md-ellipsis> Understanding pricing </span> </a> <nav class=md-nav aria-label="Understanding pricing"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scoping-workload class=md-nav__link> <span class=md-ellipsis> Scoping workload </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#disaster-recovery class=md-nav__link> <span class=md-ellipsis> Disaster Recovery </span> </a> <nav class=md-nav aria-label="Disaster Recovery"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#active-active class=md-nav__link> <span class=md-ellipsis> Active / Active </span> </a> </li> <li class=md-nav__item> <a href=#active-passive class=md-nav__link> <span class=md-ellipsis> Active / Passive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-faqs class=md-nav__link> <span class=md-ellipsis> Some FAQs </span> </a> </li> <li class=md-nav__item> <a href=#vscode-extension class=md-nav__link> <span class=md-ellipsis> VScode extension </span> </a> </li> <li class=md-nav__item> <a href=#deeper-dive class=md-nav__link> <span class=md-ellipsis> Deeper dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../cp-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Platform for Flink </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/kafka/ class=md-nav__link> <span class=md-ellipsis> Kafka Integration </span> </a> </li> <li class=md-nav__item> <a href=../cc-tableflow/ class=md-nav__link> <span class=md-ellipsis> Confluent TableFlow </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/techno/data/#data-related-technologies class=md-nav__link> <span class=md-ellipsis> Apache Iceberg </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/kafka-studies class=md-nav__link> <span class=md-ellipsis> Kafka-studies </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-nav__link> <span class=md-ellipsis> EDA </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#comparaison-with-apache-flink class=md-nav__link> <span class=md-ellipsis> Comparaison with Apache Flink </span> </a> </li> <li class=md-nav__item> <a href=#key-concepts class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> <nav class=md-nav aria-label="Key Concepts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#confluent-cloud-architecture class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Architecture </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#some-common-commands-to-manage-confluent-cloud-environment class=md-nav__link> <span class=md-ellipsis> Some common commands to manage Confluent Cloud environment </span> </a> </li> <li class=md-nav__item> <a href=#use-the-flink-sql-shell class=md-nav__link> <span class=md-ellipsis> Use the Flink SQL shell </span> </a> </li> <li class=md-nav__item> <a href=#using-the-flink-editor-in-confluent-cloud class=md-nav__link> <span class=md-ellipsis> Using the Flink editor in Confluent Cloud </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#using-the-flink-table-api class=md-nav__link> <span class=md-ellipsis> Using the Flink Table API </span> </a> </li> <li class=md-nav__item> <a href=#dlq-support class=md-nav__link> <span class=md-ellipsis> DLQ support </span> </a> </li> <li class=md-nav__item> <a href=#networking-overview class=md-nav__link> <span class=md-ellipsis> Networking overview </span> </a> </li> <li class=md-nav__item> <a href=#autopilot class=md-nav__link> <span class=md-ellipsis> Autopilot </span> </a> </li> <li class=md-nav__item> <a href=#cross-region-processing class=md-nav__link> <span class=md-ellipsis> Cross-region processing </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-and-troubleshouting class=md-nav__link> <span class=md-ellipsis> Monitoring and troubleshouting </span> </a> <nav class=md-nav aria-label="Monitoring and troubleshouting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#statement-monitoring class=md-nav__link> <span class=md-ellipsis> Statement monitoring </span> </a> </li> <li class=md-nav__item> <a href=#degraded-statement class=md-nav__link> <span class=md-ellipsis> Degraded Statement </span> </a> </li> <li class=md-nav__item> <a href=#query-profiler class=md-nav__link> <span class=md-ellipsis> Query Profiler </span> </a> </li> <li class=md-nav__item> <a href=#metrics class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> </li> <li class=md-nav__item> <a href=#compute-pool-monitoring class=md-nav__link> <span class=md-ellipsis> Compute pool monitoring </span> </a> </li> <li class=md-nav__item> <a href=#some-common-errors class=md-nav__link> <span class=md-ellipsis> Some common errors </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#role-base-access-control class=md-nav__link> <span class=md-ellipsis> Role Base Access Control </span> </a> </li> <li class=md-nav__item> <a href=#understanding-pricing class=md-nav__link> <span class=md-ellipsis> Understanding pricing </span> </a> <nav class=md-nav aria-label="Understanding pricing"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scoping-workload class=md-nav__link> <span class=md-ellipsis> Scoping workload </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#disaster-recovery class=md-nav__link> <span class=md-ellipsis> Disaster Recovery </span> </a> <nav class=md-nav aria-label="Disaster Recovery"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#active-active class=md-nav__link> <span class=md-ellipsis> Active / Active </span> </a> </li> <li class=md-nav__item> <a href=#active-passive class=md-nav__link> <span class=md-ellipsis> Active / Passive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-faqs class=md-nav__link> <span class=md-ellipsis> Some FAQs </span> </a> </li> <li class=md-nav__item> <a href=#vscode-extension class=md-nav__link> <span class=md-ellipsis> VScode extension </span> </a> </li> <li class=md-nav__item> <a href=#deeper-dive class=md-nav__link> <span class=md-ellipsis> Deeper dive </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=confluent-cloud-for-apache-flink>Confluent Cloud for Apache Flink<a class=headerlink href=#confluent-cloud-for-apache-flink title="Permanent link">&para;</a></h1> <details class="- info"> <summary>Chapter updates</summary> <ul> <li>Created 10/2024 </li> <li>Review 10/31/24 Updated 12/10/2025</li> </ul> </details> <p><a href=https://docs.confluent.io/cloud/current/flink/overview.html>Confluent Cloud for Apache Flink®</a> is a cloud-native, managed service, for Flink, strongly integrated with the Confluent Cloud Kafka managed service. It is a simple, serverless and scalable way to build real-time, reusable data products over streams.</p> <figure> <img alt src=../diagrams/ccloud-flink.drawio.png width=800> </figure> <p>Confluent Cloud Flink is built on the same open-source version as Apache Flink® with additional features:</p> <ul> <li>Regional service to run Flink in a serverless offering</li> <li>Auto-inference of the Confluent Cloud environment, Kafka cluster , topics and schemas, to Flink SQL constructs of catalog, databases and tables.</li> <li>Autoscaling capabilities, up and down</li> <li>Default system column for timestamps using the <code>$rowtime</code> column.</li> <li>Default watermark strategy based on <code>$rowtime</code>.</li> <li>Support for Avro, JSON Schema, and Protobuf.</li> <li>CREATE TABLE statements provision resources as Kafka topics and schemas (temporary tables not supported).</li> <li>Read from and write to Kafka in two modes: append-stream or update-stream (upsert and retract).</li> </ul> <p>Some <strong>limitations</strong>:</p> <ul> <li>No support for DataStream apps.</li> <li>No support or Flink connectors, only Kafka</li> </ul> <h2 id=comparaison-with-apache-flink>Comparaison with Apache Flink<a class=headerlink href=#comparaison-with-apache-flink title="Permanent link">&para;</a></h2> <p>The following table is current January 2026. Roadmap changes and product features are delivered on a weekly basis.</p> <table> <thead> <tr> <th>Apache Flink</th> <th>Confluent Cloud Flink</th> </tr> </thead> <tbody> <tr> <td>Self managed clusters, versions, state backends, checkpointing, security, connectors, and integration with Kafka and other systems</td> <td>Serverless Flink service fully managed by Confluent, tightly integrated with Confluent Cloud Kafka, Schema Registry, security, and governance</td> </tr> <tr> <td></td> <td>Create compute pools (regional, elastic resource pools) and run SQL/Table API statements against them</td> </tr> <tr> <td></td> <td>Always on the latest Flink runtime; security patches and minor upgrades are applied automatically to running statements</td> </tr> <tr> <td>Tune parallelism</td> <td>Automatically scale up or down to meet the demands of the most complex workloads without overprovisioning</td> </tr> <tr> <td>DataStream, SQL/Table API</td> <td>SQL/Table API</td> </tr> <tr> <td>Define catalogs/databases/tables, schemas, provision Kafka topic yourself.</td> <td>Environments, clusters, topics, and schemas become catalogs, databases, tables, and table schemas automatically. <code>Create table</code> provision topics and schemas</td> </tr> <tr> <td>Must define watermark strategies for event‑time processing by code</td> <td>System column $rowtime mapped to Kafka record timestamp with default watermark strategy.</td> </tr> <tr> <td>Multiple Kafka connectors, and other sources/sinks</td> <td>One Kafka connector with support to append/upsert mode from table configuration, Other system is via Confluent Cloud managed connectors</td> </tr> <tr> <td>Full SQL surface</td> <td>Limitation on Database and Catalog actions</td> </tr> <tr> <td>Integrate with your own IAM, ACLs, encryption, auditing, governance tooling</td> <td>Inherits Confluent Cloud IAM, RBAC, audit logs, and governance; Flink defines dedicated roles like FlinkDeveloper and FlinkAdmin layered on top of existing Kafka RBAC</td> </tr> <tr> <td>Support your networking integration</td> <td>NSame private networking and networking controls as Confluent Cloud Kafka (VPC peering / Private Link / CC</td> </tr> <tr> <td>Integrate metrics and logs into your own stack. Per cluster dashboard</td> <td>Confluent UI has built‑in Flink statements view, lag/throughput metrics, and error states. Native integration with Prometheus/Datadog via Confluent Cloud Metrics API and Notifications</td> </tr> </tbody> </table> <p>Pay attention that most Flink managed services are cloud-hosted and not cloud-native: only the infrastructure layer is fully managed and there’s still a lot of manual tasks for day 2 operations. </p> <p><strong>References:</strong></p> <ul> <li>Introducing Confluent Cloud for Apache Flink <a href=https://www.confluent.io/blog/introducing-flink-on-confluent-cloud/ >https://www.confluent.io/blog/introducing-flink-on-confluent-cloud/</a></li> <li>Stream Processing with Confluent Cloud for Apache Flink | <a href=https://docs.confluent.io/cloud/current/flink/overview.html>Confluent Documentation</a></li> <li>Comparing Apache Flink with Confluent Cloud for Apache Flink | <a href=https://docs.confluent.io/cloud/current/flink/concepts/comparison-with-apache-flink.html>Confluent Documentation</a></li> <li>Manage Flink Compute Pools in Confluent Cloud for Apache Flink | <a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/create-compute-pool.html>Confluent Documentation</a></li> <li>Monitor and Manage Flink SQL Statements in Confluent Cloud for Apache Flink | <a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/monitor-statements.html>Confluent Documentation</a></li> </ul> <h2 id=key-concepts>Key Concepts<a class=headerlink href=#key-concepts title="Permanent link">&para;</a></h2> <ul> <li>This is a <strong>regional service</strong>, in one of the three major cloud providers. It is defined in a context of a Confluent's environment.</li> <li><strong>Compute pools</strong> groups resources for running Flink clusters, which may scale down to zero. They run SQL <strong>statements</strong>. Maximum pool size is defined at creation. Statements, in different compute pools, are <strong>isolated</strong> from each other. </li> <li>Capacity is measured in Confluent Flink Unit, <a href=https://docs.confluent.io/cloud/current/flink/concepts/flink-billing.html#cfus>CFU</a>. Each statement is at least 1 CFU-minute.</li> <li>A statement may be structural (DDL) and stop once completed, or runs in background to write data to table (DML).</li> <li>Supports multiple Kafka clusters within the same Confluent Cloud organization in a single region.s</li> <li>Any table created in CC Flink appears as a topic in CC Kafka. Kafka Topics and schemas are always in synch with Flink.</li> <li>The differences with the OSS version, is that the DDL statements of catalog, database, table are mapped to physical Kafka objects. Table is a schema and a topic, catalog is an environment, and database is a Kafka cluster.</li> <li>Developers work in a <a href=https://www.confluent.io/blog/flink-sql-workspaces/ ><strong>workspace</strong></a>, to manage their Apache Flink® streaming applications, allowing them to easily write, execute, and monitor real-time data processing queries using a user-friendly SQL editor. Workspaces are not mandatory, as Developers may also deploy Flink statements via CLI or REST API.</li> <li>CC offers the <strong>Autopilot</strong> feature, to automatically adjusts resources for SQL statements based on demand. When messages processing starts to be behind, <strong>Autopilot</strong> adjusts resource allocation.</li> <li>Supports <a href=#role-base-access-control>role-based access control</a> for both user and service accounts.</li> <li><strong>Stream lineage</strong> provides insights at the topic level about data origin to destinations. </li> <li>For <strong>Watermark</strong> configuration, Confluent Cloud for Apache Flink® manages it automatically, by using the <code>$rowtime</code> column, which is mapped to the Kafka record timestamp, and by observing the behavior of the streams to dynamically adapt the configuration.</li> <li><a href=https://docs.confluent.io/cloud/current/security/authenticate/workload-identities/service-accounts/overview.html#service-accounts>Service accounts</a> are used for production deployment to enforce security boundaries. Permissions are done with ACL and role binding. They can own any type of API keys that can be used for CLI or API access.</li> <li> <p><a href=https://docs.confluent.io/cloud/current/flink/how-to-guides/run-snapshot-query.html#flink-sql-run-snapshot-query>Snapshot query</a> helps to do a<strong>point-in-time</strong>/snapshot query, to get a result at the moment of query submission, and that query would transition to Completed once done. Generates only one final result set. It will query from kafka topic earliest record, until now, or can mix with Tableflow parquet table. This is a combination of Flink batch + time constraint query. <div class="language-sql highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>SET</span><span class=w> </span><span class=s1>&#39;sql.snapshot.mode&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;now&#39;</span><span class=p>;</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=k>SELECT</span><span class=w> </span><span class=k>count</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>nb_records</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>tablename</span><span class=p>;</span>
</span></code></pre></div></p> <p>See <a href=https://github.com/jbcodeforce/flink-studies/tree/master/code/flink-sql/08-snapshot-query>simple demo</a></p> </li> <li> <p><a href=https://docs.confluent.io/cloud/current/ai/external-tables/overview.html>External lookups</a></p> </li> </ul> <details class="- info"> <summary>Statement life cycle</summary> <p>Use a service account for background statements. Submit a SQL statement using the client shell:</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>confluent<span class=w> </span>flink<span class=w> </span>shell<span class=w> </span>--compute-pool<span class=w> </span><span class=si>${</span><span class=nv>COMPUTE_POOL_ID</span><span class=si>}</span><span class=w> </span>--environment<span class=w> </span><span class=si>${</span><span class=nv>ENV_ID</span><span class=si>}</span><span class=w> </span>--service-account<span class=w> </span><span class=si>${</span><span class=nv>account_id</span><span class=si>}</span>
</span></code></pre></div> <p>It is possible to pause and resume a SQL statement. <a href=../../architecture/cookbook/#query-evolution>See cookbook</a> for the best practices and process to update existing statements. </p> </details> <details class="- question"> <summary>How to change the CFU limit?</summary> <p>CFU can be changed via the console or the cli, up to the limit of 50. Going above developers need to open a ticket to the Confluent support.</p> </details> <details class="- question"> <summary>What is behind a compute pool?</summary> <p>A compute pool groups 1 job manager and n task manager. Task manager resource configuration is not configurable and is designed to support small usage as well as moderate traffic. The limit to 50 CFUs is to address trade-off between coordination overhead and scaling needs. A Flink dag with source and sink operators impact the throughput of task manager so it is always challenging to assess how many task manager to be support by a job manager. Large states are persisted to disk and this impact the compute pool resources too. </p> <ul> <li>Statement can be moved between compute pools</li> </ul> </details> <h3 id=confluent-cloud-architecture>Confluent Cloud Architecture<a class=headerlink href=#confluent-cloud-architecture title="Permanent link">&para;</a></h3> <p>The Confluent Cloud for Kafka and for Flink is based on the SaaS pattern of control and data planes. <a href=https://youtu.be/ss5OEBejFCs>See this presentation - video from Frank Greco Jr</a>.</p> <figure> <img alt src=../diagrams/ccloud-architecture.drawio.png> </figure> <ul> <li>Each data plane is made of a VPC, a kubernetes cluster, a set of Kafka clusters and some management services to support platform management and communication with the control plane.</li> <li>The control plane is called the <em>mothership</em>, and refers to VPC, services, Database to manage the multi-tenancy platform, a kubernetes cluster, Kafka cluster, and other components. This is where the Confluent console runs for users to administer the Kafka clusters. </li> <li>For each data plane VPC, outbound connections are allowed through internet gateways.</li> <li>There is a scheduler service to provision resources or assign cluster to existing resources. Target states are saved in a SQL database, while states are propagated from the different data planes to the mothership. This communication is async and leverage a global Kafka cluster.</li> <li>There are the concepts of physical Kafka clusters and logical clusters. Logical clusters are groupings of topics on the physical clusters isolated from each other via a prefix. Professional Confluent Cloud organization can only have logical clusters. Enterprise can have physical clusters.</li> </ul> <h2 id=getting-started>Getting Started<a class=headerlink href=#getting-started title="Permanent link">&para;</a></h2> <p>Install the <a href=https://docs.confluent.io/confluent-cli/current/overview.html>Confluent CLI</a> and get an Confluent Cloud account. </p> <p>See those tutorials for getting started.</p> <ul> <li><a href=https://docs.confluent.io/cloud/current/flink/get-started/quick-start-cloud-console.html>Quickstart with Console</a></li> <li><a href=https://developer.confluent.io/courses/flink-sql/overview/ >Apache Flink® SQL</a></li> <li><a href=https://github.com/confluentinc/confluent-cloud-flink-workshop/tree/master/flink-getting-started>Confluent github, Flink workshop</a></li> <li><a href=https://docs.confluent.io/cloud/current/flink/get-started/quick-start-java-table-api.html>Java Table API Quick Start</a></li> </ul> <p>There is also a new confluent cli plugin: <code>confluent-flink-quickstart</code> to create an environment, a Flink compute pool, enable a schema registry, create a Kafka cluster and starts a Flink shell. </p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>confluent<span class=w> </span>flink<span class=w> </span>quickstart<span class=w> </span>--name<span class=w> </span>my-flink-sql<span class=w> </span>--max-cfu<span class=w> </span><span class=m>10</span><span class=w> </span>--region<span class=w> </span>us-west-2<span class=w> </span>--cloud<span class=w> </span>aws
</span></code></pre></div> <h3 id=some-common-commands-to-manage-confluent-cloud-environment>Some common commands to manage Confluent Cloud environment<a class=headerlink href=#some-common-commands-to-manage-confluent-cloud-environment title="Permanent link">&para;</a></h3> <div class="language-sh highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Create an environment</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>confluent<span class=w> </span>environment<span class=w> </span>create<span class=w> </span>my_environment<span class=w> </span>--governance-package<span class=w> </span>essentials
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># Set the active environment.</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>confluent<span class=w> </span>environment<span class=w> </span>use<span class=w> </span>&lt;environment<span class=w> </span>id&gt;
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=c1># Create a cluster</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>confluent<span class=w> </span>Kafka<span class=w> </span>cluster<span class=w> </span>create<span class=w> </span>my-cluster<span class=w> </span>--cloud<span class=w> </span>gcp<span class=w> </span>--region<span class=w> </span>us-central1<span class=w> </span>--type<span class=w> </span>basic
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=c1># Create Kafka API key</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>confluent<span class=w> </span>Kafka<span class=w> </span>cluster<span class=w> </span>list
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=nb>export</span><span class=w> </span><span class=nv>CLID</span><span class=o>=</span>&lt;Kafka<span class=w> </span>cluster<span class=w> </span>id&gt;
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>confluent<span class=w> </span>api-key<span class=w> </span>create<span class=w> </span>--resource<span class=w> </span><span class=nv>$CLID</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=c1># Create a compute pool (adjust cloud and region settings as required).</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>confluent<span class=w> </span>flink<span class=w> </span>compute-pool<span class=w> </span>create<span class=w> </span>my-compute-pool<span class=w> </span>--cloud<span class=w> </span>gcp<span class=w> </span>--region<span class=w> </span>us-central1<span class=w> </span>--max-cfu<span class=w> </span><span class=m>10</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a><span class=c1># Create a Flink api key which is scoped in an environment + region pair</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>confluent<span class=w> </span>api-key<span class=w> </span>create<span class=w> </span>--resource<span class=w> </span>flink<span class=w> </span>--cloud<span class=w> </span>gcp<span class=w> </span>--region<span class=w> </span>us-central1
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a><span class=c1># Define an api key for schema registry</span>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a>confluent<span class=w> </span>schema-registry<span class=w> </span>cluster<span class=w> </span>describe
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a>confluent<span class=w> </span>api-key<span class=w> </span>create<span class=w> </span>--resource<span class=w> </span>&lt;schema<span class=w> </span>registry<span class=w> </span>cluster&gt;
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a><span class=c1># Get the user id</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>confluent<span class=w> </span>iam<span class=w> </span>user<span class=w> </span>list
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a><span class=c1># To shutdown everything:</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a>confluent<span class=w> </span>environment<span class=w> </span>list
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a>confluent<span class=w> </span>environment<span class=w> </span>delete<span class=w> </span>&lt;ENVIRONMENT_ID&gt;
</span></code></pre></div> <p>For study and demonstration purpose, there is a read-only catalog named <a href=https://docs.confluent.io/cloud/current/flink/reference/example-data.html><code>examples</code></a> with database called <code>marketplace</code> which has data generators for different SQL tables. </p> <p>Set the namespace for future query work using:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=n>use</span><span class=w> </span><span class=k>catalog</span><span class=w> </span><span class=n>examples</span><span class=p>;</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>use</span><span class=w> </span><span class=n>marketplace</span><span class=p>;</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=k>show</span><span class=w> </span><span class=n>tables</span><span class=p>;</span>
</span></code></pre></div> <p>To use your dedicated environment use the following syntax:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>use</span><span class=w> </span><span class=k>catalog</span><span class=w> </span><span class=n>my</span><span class=o>-</span><span class=n>flink</span><span class=o>-</span><span class=n>sql_environment</span><span class=p>;</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>use</span><span class=w>  </span><span class=n>my</span><span class=o>-</span><span class=n>flink</span><span class=o>-</span><span class=n>sql_Kafka</span><span class=o>-</span><span class=k>cluster</span><span class=p>;</span>
</span></code></pre></div> <h3 id=use-the-flink-sql-shell>Use the Flink SQL shell<a class=headerlink href=#use-the-flink-sql-shell title="Permanent link">&para;</a></h3> <p>Using the confluent cli, we can access to the client via:</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1>#  </span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>confluent<span class=w> </span>environment<span class=w> </span>list
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># Get the compute pool id</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>confluent<span class=w> </span>flink<span class=w> </span>compute-pool<span class=w> </span>list
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=nb>export</span><span class=w> </span><span class=nv>ENV_ID</span><span class=o>=</span><span class=k>$(</span>confluent<span class=w> </span>environment<span class=w> </span>list<span class=w> </span>-o<span class=w> </span>json<span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.[] | select(.name == &quot;aws-west&quot;) | .id&#39;</span><span class=k>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=nb>export</span><span class=w> </span><span class=nv>COMPUTE_POOL_ID</span><span class=o>=</span><span class=k>$(</span>confluent<span class=w> </span>flink<span class=w> </span>compute-pool<span class=w> </span>list<span class=w> </span>-o<span class=w> </span>json<span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.[0].id&#39;</span><span class=k>)</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>confluent<span class=w> </span>flink<span class=w> </span>shell<span class=w> </span>--compute-pool<span class=w> </span><span class=nv>$COMPUTE_POOL_ID</span><span class=w> </span>--environment<span class=w> </span><span class=nv>$ENV_ID</span>
</span></code></pre></div> <h3 id=using-the-flink-editor-in-confluent-cloud>Using the Flink editor in Confluent Cloud<a class=headerlink href=#using-the-flink-editor-in-confluent-cloud title="Permanent link">&para;</a></h3> <p>Nothing special to mention, except that users need to recall that once the job is started, they cannot modify it:they need to stop before any future edition. Restarting may mean reprocess from the earliest records. It is recommended to persist the Flink statement in a git repository and manage the deployment using Confluent CLI or the <a href=https://jbcodeforce.github.io/shift_left_utils/blue_green_deploy/ >shift_left CLI tool</a>.</p> <h2 id=using-the-flink-table-api>Using the Flink Table API<a class=headerlink href=#using-the-flink-table-api title="Permanent link">&para;</a></h2> <p>Confluent Cloud for Flink <a href=https://docs.confluent.io/cloud/current/flink/get-started/quick-start-java-table-api.html>supports the Table API, in Java</a> or <a href=https://docs.confluent.io/cloud/current/flink/get-started/quick-start-python-table-api.html>Python</a>.</p> <p>The <a href=../../coding/table-api/ >Table API</a> code is a client SDK, it communicates with Confluent Cloud by using REST requests to send SQL statement to the job manager and is interpreted by the SQL engine. </p> <p>The Table API program acts as a client-side library for interacting with the Flink engine hosted in the cloud. It enables the submission of <code>Statements</code> and retrieval of <code>StatementResults</code>. The provided Confluent plugin integrates specific components for configuring the TableEnvironment, eliminating the need for a local Flink cluster. By including the <code>confluent-flink-table-api-java-plugin</code> dependency, Flink's internal components—such as CatalogStore, Catalog, Planner, Executor, and configuration, are managed by the plugin and fully integrated with Confluent Cloud. This integration is via the REST API, so Confluent Table API plugin is an higher emcapsulation of the CC REST API. </p> <p>The code runs on an external systems, but uses an specific Flink environment for Confluent Cloud to submit the DAG to the remote engine.</p> <p>When running TableAPI with Confluent Cloud for Flink plugin, we need to provide <a href=https://docs.confluent.io/cloud/current/flink/reference/table-api.html#configure-the-plugin>configurations</a> via properties file or Environment variables. </p> <ol> <li> <p>Set the environment variables to connect to Confluent Cloud: <div class="language-sh highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=nb>export</span><span class=w> </span><span class=nv>FLINK_API_KEY</span><span class=o>=</span><span class=s2>&quot;&lt;your-flink-api-key&gt;&quot;</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=nb>export</span><span class=w> </span><span class=nv>FLINK_API_SECRET</span><span class=o>=</span><span class=s2>&quot;&lt;your-flink-api-secret&gt;&quot;</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=nb>export</span><span class=w> </span><span class=nv>ORG_ID</span><span class=o>=</span><span class=s2>&quot;&lt;your-organization-id&gt;&quot;</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=nb>export</span><span class=w> </span><span class=nv>ENV_ID</span><span class=o>=</span><span class=s2>&quot;&lt;your-environment-id&gt;&quot;</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=nb>export</span><span class=w> </span><span class=nv>COMPUTE_POOL_ID</span><span class=o>=</span><span class=s2>&quot;&lt;your-compute-pool-id&gt;&quot;</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=nb>export</span><span class=w> </span><span class=nv>CLOUD_PROVIDER</span><span class=o>=</span><span class=s2>&quot;aws&quot;</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=nb>export</span><span class=w> </span><span class=nv>CLOUD_REGION</span><span class=o>=</span><span class=s2>&quot;us-east-1&quot;</span>
</span></code></pre></div></p> </li> <li> <p>Create a Table environment in the Java or Python, using the template approach for URLs: <div class="language-java highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=n>ConfluentSettings</span><span class=w> </span><span class=n>settings1</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>ConfluentSettings</span><span class=p>.</span><span class=na>newBuilder</span><span class=p>()</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=w>  </span><span class=p>.</span><span class=na>setRegion</span><span class=p>(</span><span class=s>&quot;us-east-1&quot;</span><span class=p>)</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=w>  </span><span class=p>.</span><span class=na>setCloud</span><span class=p>(</span><span class=s>&quot;aws&quot;</span><span class=p>)</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=w>  </span><span class=p>.</span><span class=na>setEndpointTemplate</span><span class=p>(</span><span class=s>&quot;https://flinkpls-dom123.{region}.{cloud}.confluent.cloud&quot;</span><span class=p>)</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=w>  </span><span class=p>.</span><span class=na>setArtifactEndpointTemplate</span><span class=p>(</span><span class=s>&quot;https://artifacts.{region}.{cloud}.custom-domain.com&quot;</span><span class=p>)</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=w>  </span><span class=c1>// Other required settings...</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=w>  </span><span class=p>.</span><span class=na>build</span><span class=p>();</span>
</span></code></pre></div></p> </li> <li> <p>Package and run</p> </li> </ol> <p><a href=../../coding/table-api/ >Read this chapter</a> for more information.</p> <h2 id=dlq-support>DLQ support<a class=headerlink href=#dlq-support title="Permanent link">&para;</a></h2> <p>In production deployment, Flink statements may fail because of serialization errors due to one of the following reasons:</p> <ul> <li>Schema does not exists</li> <li>There are one or more bad messages in the topic that are not compliant with the schema</li> <li>Got some connection challenge to the schema registry</li> </ul> <p>Dead Letter Queue is now supported via SQL configuration to the underlying Kafka connector. By integrating Custom Deserialization Error Handling Strategies, data engineers can ensure that only valid, correctly processed messages move downstream, maintaining data quality and integrity. This feature reduces the risk of system crashes and downtime caused by unhandled exceptions, ensuring continuous data processing and availability.</p> <p>In order to re-process the data, the Data engineer will have to write a specific SQL statement that reads from the DLQ. </p> <p>For certain queries (like stateful operations, such as joins) data engineers need to consider that reprocessing DLQ data at a later moment will result in incorrect results downstream, because of the order in how data is being processed. If correct results are required, the only solution will be to fully reprocess data from a topic without bad messages.</p> <p>All Flink tables have <code>error-handling.mode</code> as a table option, with the default being <code>fail</code>. <a href=https://docs.confluent.io/cloud/current/flink/reference/statements/create-table.html#flink-sql-create-table-with-error-handling-mode>See product documentation.</a></p> <ul> <li> <p>If desired, you can run an ALTER TABLE to change this to <code>ignore</code> or <code>log</code>. Those alteration should be done to topics created outside of CREATE table done with Flink SQL. The CDC output topics are good candidates for such modifications.</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=k>ALTER</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>raw_users_table</span><span class=w> </span><span class=k>SET</span><span class=w> </span><span class=p>(</span><span class=s1>&#39;error-handling.mode&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;log&#39;</span><span class=p>);</span>
</span></code></pre></div> <p>The DLQ topic uses a specific generic DLQ schema, which includes information such as the key and value as bytes (since deserialization failed, there’s nothing else to represent), plus the schema ID that was being tried. It includes metadata like error message and the statement ID that triggers the error. </p> </li> <li> <p>or add this config to the created table: <div class="language-text highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a>create table src_users_table (...) WITH (
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>    ....
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    &#39;error-handling.mode&#39; = &#39;log&#39;
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>)
</span></code></pre></div></p> </li> </ul> <details class="- warning"> <summary>Potential error</summary> <p>It is possible to get the following error when altering table failed registering schemas: unable to register schema on 'error_log-value': schema registry request failed error code: 42205: Subject error_log-value in context is not in read-write mode. In this case, you will run into this error as flink is trying to register a schema for the DLQ and Schema Regisry is being schema-linked as a result the default context is in Read only mode. You need to create your own DLQ table. </p> </details> <ul> <li> <p>Or create a special DLQ topic: <div class="language-sql highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=o>`</span><span class=n>my_error_log</span><span class=o>`</span><span class=w> </span><span class=p>(</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=w>    </span><span class=o>`</span><span class=n>error_timestamp</span><span class=o>`</span><span class=w> </span><span class=n>TIMESTAMP_LTZ</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=w>    </span><span class=o>`</span><span class=n>error_code</span><span class=o>`</span><span class=w> </span><span class=nb>INT</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=w>    </span><span class=o>`</span><span class=n>error_reason</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=w>    </span><span class=o>`</span><span class=n>error_message</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=w>    </span><span class=o>`</span><span class=n>error_details</span><span class=o>`</span><span class=w> </span><span class=k>MAP</span><span class=o>&lt;</span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w> </span><span class=n>STRING</span><span class=o>&gt;</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=w>    </span><span class=o>`</span><span class=n>processor</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=w>    </span><span class=o>`</span><span class=n>statement_name</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a><span class=w>    </span><span class=o>`</span><span class=n>affected_type</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a><span class=w>    </span><span class=o>`</span><span class=n>affected_catalog</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a><span class=w>    </span><span class=o>`</span><span class=n>affected_database</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a><span class=w>    </span><span class=o>`</span><span class=n>affected_name</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a><span class=w>    </span><span class=o>`</span><span class=n>source_record</span><span class=o>`</span><span class=w> </span><span class=k>ROW</span><span class=o>&lt;`</span><span class=n>topic</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=n>partition</span><span class=o>`</span><span class=w> </span><span class=nb>INT</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=k>offset</span><span class=o>`</span><span class=w> </span><span class=nb>BIGINT</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=k>timestamp</span><span class=o>`</span><span class=w> </span><span class=n>TIMESTAMP_LTZ</span><span class=p>(</span><span class=mi>3</span><span class=p>),</span><span class=w> </span><span class=o>`</span><span class=n>timestamp_type</span><span class=o>`</span><span class=w> </span><span class=n>STRING</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=n>headers</span><span class=o>`</span><span class=w> </span><span class=k>MAP</span><span class=o>&lt;</span><span class=n>STRING</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w> </span><span class=n>VARBINARY</span><span class=o>&gt;</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=k>key</span><span class=o>`</span><span class=w> </span><span class=n>VARBINARY</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=n>value</span><span class=o>`</span><span class=w> </span><span class=n>VARBINARY</span><span class=o>&gt;</span>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=p>)</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=p>(</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a><span class=w>    </span><span class=s1>&#39;value.avro-registry.schema-context&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;.flink-stage&#39;</span><span class=p>,</span>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a><span class=w>    </span><span class=s1>&#39;value.format&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;avro-registry&#39;</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a><span class=w>    </span><span class=p>)</span>
</span></code></pre></div></p> <p>Alter the source table to enable with a DLQ that was created above.</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>ALTER</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>src_users_table</span><span class=w> </span><span class=k>SET</span><span class=w> </span><span class=p>(</span><span class=s1>&#39;error-handling.mode&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;log&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;error-handling.log.target&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;my_error_log&#39;</span><span class=w> </span><span class=p>);</span>
</span></code></pre></div> </li> </ul> <h2 id=networking-overview>Networking overview<a class=headerlink href=#networking-overview title="Permanent link">&para;</a></h2> <p><a href=https://docs.confluent.io/cloud/current/networking/overview.html>See the product documentation for managing Networking on Confluent Cloud.</a> </p> <p>Kafka clusters have the following properties:</p> <ul> <li>Basic and standard clusters are multi-tenant and accessible via secured (TLS encrypted) public endpoints.</li> <li>Using private link does not expose Kafka clusters to the public.</li> <li>Enterprise clusters are accessible through secure AWS PrivateLink or Azure Private Link connections.</li> <li>Secure public endpoints are protected by a proxy layer that prevents types of DoS, DDoS, syn flooding, and other network-level attacks.</li> <li>A Confluent Cloud network is an abstraction for a single tenant network environment. <a href=https://docs.confluent.io/cloud/current/networking/ccloud-network/aws.html#create-ccloud-network-aws>See setup CC network on AWS.</a>. </li> <li>For AWS and Confluent Dedicated Clusters, networking can be done via VPC peering, transit gateway, inbound and outbound private link (for Kafka and Flink): this is a one-way connection access from a VPC to CC.</li> <li>Flink Private Networking requires a <a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/private-networking.html#create-a-pla-overview>PrivateLink Attachment</a> (PLATT) to access Kafka clusters with private networking. It is used to connect clients such as confluent CLI, the console, the rest api or terraform with Flink. Flink-to-Kafka is routed internally within Confluent Cloud.</li> </ul> <figure> <img alt src=../images/flink-private-networking.svg> </figure> <ul> <li>PLATT is independant of the network type: PrivateLink, VPC peering or transit GTW.</li> </ul> <h2 id=autopilot>Autopilot<a class=headerlink href=#autopilot title="Permanent link">&para;</a></h2> <p><a href=https://docs.confluent.io/cloud/current/flink/concepts/autopilot.html>Autopilot</a> automatically scales up and down compute pool resources needed by SQL statements. It uses the property of parallelism for operator to be able to scale up and down. <code>SELECT</code> always runs a parallelism of 1. Only <code>CREATE TABLE AS</code>, <code>INSERT INTO</code> and <code>EXECUTE STATEMENT SET</code> are considered by Autopilot for scaling. Global aggregate are not parallelized. The main goal of the auto scaler is to maintain optimum throughput and number of resources (or CFUs). </p> <p>The SQL workspace reports the <a href=https://docs.confluent.io/cloud/current/flink/concepts/autopilot.html#scaling-status>scaling status</a>. It is important that each job has a maximum parallelism, limited by the number of resource available. For source operators within a Flink DAG the limit is the number of partitions in the input topics. </p> <p>If there is some data skew and one operator is set with a parallel of 1 then there is no need to scale.</p> <p>When the compute pool is exhausted, try to add more CFU or stop some running statements to free up resources.</p> <p>The autoscaler is using historical metrics to take the decision to scale up. 3 to 4 minutes of data are needed. A job should scale up within minutes if the backlog is constantly growing, and scale down if there are no input data and the backlog. The interesting metrics is the pending records. The algorithm needs to take into account the pending records amount, the current processing capacity, the time to scale up, but also the input data rate, the output data rate for each operator in the DAG. There is no way updfront to estimate the needed capacity. This is why it is important to assess the raw input table/kafka size and avoid restarting the first Flink statements that are filtering, deduplicating records to reduce the number of messages to process downstream of the data pipeline.</p> <p>Autopilot exposes the CFU usage in CFU minutes via the metrics API at the compute pool level.</p> <p>When multiple statements are in the same compute pool, new statement will not get resource until existing one scales down. Consider looking at Statement in Pending state and reallocated them to other compute pool. The total number of jobs is less than the CFU limit.</p> <details class="- question"> <summary>When a statement is not scaling up what can be done?</summary> <div class=codehilite><pre><span></span><code><span class=nv>Consider</span><span class=w> </span><span class=nv>looking</span><span class=w> </span><span class=nv>at</span><span class=w> </span><span class=nv>the</span><span class=w> </span><span class=nv>CFU</span><span class=w> </span><span class=nv>limit</span><span class=w> </span><span class=nv>of</span><span class=w> </span><span class=nv>the</span><span class=w> </span><span class=nv>compute</span><span class=w> </span><span class=nv>poolas</span><span class=w> </span><span class=nv>it</span><span class=w> </span><span class=nv>may</span><span class=w> </span><span class=nv>has</span><span class=w> </span><span class=nv>been</span><span class=w> </span><span class=nv>reached</span>.<span class=w> </span><span class=nv>The</span><span class=w> </span><span class=nv>Flink</span><span class=w> </span><span class=nv>job</span><span class=w> </span><span class=nv>may</span><span class=w> </span><span class=nv>have</span><span class=w> </span><span class=nv>reached</span><span class=w> </span><span class=nv>it</span>’<span class=nv>s</span><span class=w> </span><span class=nv>effective</span><span class=w> </span><span class=nv>max</span><span class=w> </span><span class=nv>parallelism</span>,<span class=w> </span><span class=nv>due</span><span class=w> </span><span class=nv>to</span><span class=w> </span><span class=nv>not</span><span class=w> </span><span class=nv>enough</span><span class=w> </span><span class=nv>Kafka</span><span class=w> </span><span class=nv>topic</span><span class=w> </span><span class=nv>partition</span><span class=w> </span><span class=nv>from</span><span class=w> </span><span class=nv>the</span><span class=w> </span><span class=nv>input</span><span class=w> </span><span class=nv>tables</span>.<span class=w> </span><span class=nv>Consider</span><span class=w> </span><span class=nv>looking</span><span class=w> </span><span class=nv>at</span><span class=w> </span><span class=nv>the</span><span class=w> </span><span class=nv>data</span><span class=w> </span><span class=nv>skew</span>,<span class=w> </span><span class=nv>as</span><span class=w> </span><span class=nv>a</span><span class=w> </span><span class=nv>potential</span><span class=w> </span><span class=nv>cause</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=nv>scale</span><span class=o>-</span><span class=nv>ups</span><span class=w> </span><span class=nv>inefficiency</span>.<span class=w> </span>
<span class=nv>Internally</span><span class=w> </span><span class=nv>to</span><span class=w> </span><span class=nv>Confluent</span><span class=w> </span><span class=nv>Cloud</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=nv>Flink</span>,<span class=w> </span><span class=nv>checkpoints</span><span class=w> </span><span class=nv>may</span><span class=w> </span><span class=nv>take</span><span class=w> </span><span class=nv>a</span><span class=w> </span><span class=nv>long</span><span class=w> </span><span class=nv>time</span>.<span class=w> </span><span class=nv>The</span><span class=w> </span><span class=nv>autopilot</span><span class=w> </span><span class=nv>may</span><span class=w> </span><span class=nv>rescale</span><span class=w> </span><span class=nv>only</span><span class=w> </span><span class=nv>after</span><span class=w> </span><span class=nv>the</span><span class=w> </span><span class=nv>current</span><span class=w> </span><span class=nv>checkpoint</span><span class=w> </span><span class=nv>has</span><span class=w> </span><span class=nv>completed</span><span class=w> </span><span class=nv>or</span><span class=w> </span><span class=mi>2</span><span class=w> </span><span class=nv>checkpoints</span><span class=w> </span><span class=nv>have</span><span class=w> </span><span class=nv>failed</span><span class=w> </span><span class=nv>in</span><span class=w> </span><span class=nv>a</span><span class=w> </span><span class=nv>row</span>.
</code></pre></div> </details> <p><a href=https://cwiki.apache.org/confluence/display/FLINK/FLIP-291%3A+Externalized+Declarative+Resource+Management>See discussion of adaptive scheduler from Flink FLIP-291.</a></p> <h2 id=cross-region-processing>Cross-region processing<a class=headerlink href=#cross-region-processing title="Permanent link">&para;</a></h2> <p>Within an environment, there is one schema registry. We can have multiple Kafka clusters per region and multiple Flink compute pools per region. Any tables created in both region with the same name will have the value and key schemas shared in the central schema registry. The SQL Metastore, Flink compute pools and Kafka clusters are regional. </p> <h2 id=monitoring-and-troubleshouting>Monitoring and troubleshouting<a class=headerlink href=#monitoring-and-troubleshouting title="Permanent link">&para;</a></h2> <p><a href=https://docs.confluent.io/cloud/current/monitoring/metrics-api.html>The metrics API documentation.</a></p> <p>You must create an API key to authenticate your requests to the Metrics API.</p> <h3 id=statement-monitoring>Statement monitoring<a class=headerlink href=#statement-monitoring title="Permanent link">&para;</a></h3> <p>Once the Flink SQL statement runs, Data Engineers may use the Console, (Environment &gt; Flink &gt; Flink page &gt; Flink statements) to assess the list of statements and their state of processing. The <a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/monitor-statements.html>product documentation - Monitoring and manage Flink SQL statements</a> goes into the details of it.</p> <figure> <img alt src=../images/statement_list.png> </figure> <p>See the <a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/monitor-statements.html>monitoring product documentation</a> for explanations of the different fields. The following fields are important to consider:</p> <table> <thead> <tr> <th>Field</th> <th>Why to consider</th> </tr> </thead> <tbody> <tr> <td><strong>Status</strong></td> <td>Verify the state of the Flink query</td> </tr> <tr> <td><strong>Statement CFU</strong></td> <td>Server resource used by the statement</td> </tr> <tr> <td><strong>Messages Behind</strong></td> <td>Is the query behind, is there some backpressure applied</td> </tr> <tr> <td><strong>Message out</strong></td> <td>Rate of messages created by the query</td> </tr> <tr> <td><strong>State Size</strong> in GB</td> <td>Keep it low, alert at 300+ GB</td> </tr> </tbody> </table> <p>Look at the statement status, consider failed, pending, degraded. Some issues are recoverables, some not:</p> <table> <thead> <tr> <th></th> <th>Recoverable</th> <th>Non-recoverable</th> </tr> </thead> <tbody> <tr> <td><strong>User</strong></td> <td>Kafka topic deletion, loss of access to cloud resources</td> <td>De/Serialization exception, arithmetic exception, any exception thrown in user code</td> </tr> <tr> <td><strong>System</strong></td> <td>checkpointing failure, networking disruption</td> <td></td> </tr> <tr> <td><strong>Actions</strong></td> <td>If recovery takes a long time or fails repeatedly, and if this is a user execption, the message will be in the status.detail of the statement, else the user may reach to the support.</td> <td>User needs to fix the query or data.</td> </tr> </tbody> </table> <p>Be sure to enable cloud notifications and at least monitor topic consumer lag metric. As a general practices, monitoring for <code>current_cfus = cfu_limit</code> to avoid exhaustion of compute pools. </p> <p>The <code>flink/pending.records</code> is the most important metrics to consider. It corresponds to consumer lag in Kafka and “Messages Behind” in the Confluent Cloud UI. Monitor for high and increasing consumer lag.</p> <p>At the Statement level we can get the following metrics, over time:</p> <p><img alt src=../images/statement_metrics.png></p> <h3 id=degraded-statement>Degraded Statement<a class=headerlink href=#degraded-statement title="Permanent link">&para;</a></h3> <p><a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/monitor-statements.html#degraded-statements>In degraded mode, statement could not make progress.</a>.</p> <p>For internal system error, this may be linked to resources issue. <a href=https://docs.confluent.io/cloud/current/flink/how-to-guides/resolve-common-query-problems.html#flink-sql-statement-problems>See standard resolution approaches:</a></p> <ul> <li>run your query with the EXPLAIN </li> <li>Access Queery Profiler to look for bottlenexts, data flow issue at the operator level.</li> <li>Verify CFU usage</li> </ul> <h3 id=query-profiler>Query Profiler<a class=headerlink href=#query-profiler title="Permanent link">&para;</a></h3> <p><a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/query-profiler.html>Query Profiler</a> helps developers to get visibility into each operator of the query DAG, with metrcis like CPU utilization, state size, ...</p> <p><img alt src=../images/statement_query_profiler.png></p> <p>Developers can now visualize data flow, track data volume processed by each operator, and identify operators experiencing high latency, unbounded state growth, or backpressure.</p> <p>As explained <a href=http://localhost:8000/flink-studies/concepts/#dataflow>in Flink Dataflow concept</a>, a task is responsible for executing a specific part of the data processing logics. As a task may be divided into multiple subtasks, the metrics at the task level will be calculated by aggregating together the metrics from the subtasks inside the task. </p> <p>As Flink optimizes the operators execution plan, so operator level metrics are also reported. Operators which are chained together form tasks, tasks will be presented visually by grouping operators together inside a rectangle.</p> <p>Consider assessing the following metrics:</p> <ul> <li>Backpressure</li> <li>Busyness</li> <li>Bytes in and out</li> <li>State Size</li> <li>Watermark</li> </ul> <p><strong>watermark and watermark alignment</strong> status is presenter for the partitions in a Kafka topic that Flink reads data from. The watermark alignment status has 3 columns: blocked, active, idle with percentages to represent <em>how much time the Kafka partition</em> is contributing to watermark alignment. Partition watermarks metric is available for Flink source operators only. Developer may be able to see <strong>idle partitions</strong>, or idleness behavior over time (this last issue may impact the record processing with delay from second to several minutes).</p> <figure> <img alt src=../images/wm_metrics.png> </figure> <p>Metric skew is presented at the task level. The skew tell developers if there is a particular subtask inside the task that is problematic and they then may take the relevant actions to fix it. Data skew metrics are for throughput, state size, busyness and backpressure. They are aggregated up to create task level and operator level. Data skew indicates the degree of variation in these performance metrics across subtasks and operators, telling developers how well balanced the workloads are. </p> <p>In Confluent Cloud, Flink uses kafka topic/partition as sources and sinks. The topic partitioning significantly increases scalability and performance as it allows for higher throughput of message processing. This applies to the Flink sources or sink connectors.</p> <p><em>A Flink statement, is a Flink application, but the Flink UI is not exposed. This WebApp uses an old software stack, that may not fit well in modern SaaS platform.</em></p> <details class=info open=open> <summary>EXPLAIN vs Query Profiler</summary> <p>The EXPLAIN command outputs the Flink query plan showing the operations that Flink will execute and the changelog mode used to handle state updates. This gives users insight into how Flink understands and plans to execute the Statement. Developers use it during development and adjustment. There is no data metrics.</p> <p>Query profiler is dynamic with data metrics. It helps developers to diagnose performance issues during or after statement execution.</p> </details> <p><a href=https://docs.confluent.io/cloud/current/flink/how-to-guides/profile-query.html#flink-sql-profile-query>See the product demonstration - how to guide</a> to analyze a temporal join with EXPLAIN and Query profiler. To avoid statement to stop change the SQL as: <div class="language-sql highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=k>create</span><span class=w> </span><span class=k>table</span><span class=w> </span><span class=n>last_orders</span><span class=p>(</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=w>  </span><span class=n>order_id</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>(</span><span class=mi>2147483647</span><span class=p>)</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>not</span><span class=w> </span><span class=n>enforced</span><span class=p>,</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=w>  </span><span class=n>ts</span><span class=w> </span><span class=n>TIMESTAMP_LTZ</span><span class=p>(</span><span class=mi>3</span><span class=p>),</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=w>  </span><span class=n>customer_id</span><span class=w> </span><span class=nb>INT</span><span class=p>,</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=w>  </span><span class=n>product_id</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>(</span><span class=mi>2147483647</span><span class=p>),</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=w>  </span><span class=n>name</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>(</span><span class=mi>2147483647</span><span class=p>),</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=w>  </span><span class=n>email</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>(</span><span class=mi>2147483647</span><span class=p>),</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=w>  </span><span class=n>price</span><span class=w> </span><span class=n>DOUBLE</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a><span class=p>)</span><span class=w> </span><span class=n>DISTRIBUTED</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=p>(</span><span class=n>order_id</span><span class=p>)</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=p>(</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a><span class=w>  </span><span class=s1>&#39;changelog.mode&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;upsert&#39;</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a><span class=k>SELECT</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a><span class=w>  </span><span class=n>o</span><span class=p>.</span><span class=n>order_id</span><span class=p>,</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a><span class=w>  </span><span class=n>o</span><span class=p>.</span><span class=o>`</span><span class=err>$</span><span class=n>rowtime</span><span class=o>`</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>ts</span><span class=p>,</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a><span class=w>  </span><span class=k>c</span><span class=p>.</span><span class=n>customer_id</span><span class=p>,</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a><span class=w>  </span><span class=n>o</span><span class=p>.</span><span class=n>product_id</span><span class=p>,</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a><span class=w>  </span><span class=k>c</span><span class=p>.</span><span class=n>name</span><span class=p>,</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a><span class=w>  </span><span class=k>c</span><span class=p>.</span><span class=n>email</span><span class=p>,</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a><span class=w>  </span><span class=n>o</span><span class=p>.</span><span class=n>price</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a><span class=k>FROM</span><span class=w> </span><span class=n>examples</span><span class=p>.</span><span class=n>marketplace</span><span class=p>.</span><span class=n>orders</span><span class=w> </span><span class=n>o</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a><span class=k>JOIN</span><span class=w> </span><span class=n>examples</span><span class=p>.</span><span class=n>marketplace</span><span class=p>.</span><span class=n>customers</span><span class=w> </span><span class=k>FOR</span><span class=w> </span><span class=n>SYSTEM_TIME</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=k>OF</span><span class=w> </span><span class=n>o</span><span class=p>.</span><span class=o>`</span><span class=err>$</span><span class=n>rowtime</span><span class=o>`</span><span class=w> </span><span class=k>c</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a><span class=k>ON</span><span class=w> </span><span class=n>o</span><span class=p>.</span><span class=n>customer_id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>c</span><span class=p>.</span><span class=n>customer_id</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a><span class=k>WHERE</span><span class=w> </span><span class=n>o</span><span class=p>.</span><span class=o>`</span><span class=err>$</span><span class=n>rowtime</span><span class=o>`</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=k>CURRENT_TIMESTAMP</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=s1>&#39;1&#39;</span><span class=w> </span><span class=n>HOUR</span><span class=p>;</span>
</span></code></pre></div></p> <h3 id=metrics>Metrics<a class=headerlink href=#metrics title="Permanent link">&para;</a></h3> <ul> <li>Confluent Cloud for Apache Flink supports metrics integrations with services like Prometheus, Grafana and Datadog.</li> </ul> <figure> <img alt src=../images/export_metrics.png> </figure> <ul> <li><a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/monitor-statements.html>Flink monitoring statement product documentation</a></li> <li><a href=https://github.com/confluentinc/confluent-cloud-flink-workshop/tree/master/flink-monitoring>Docker compose, Prometheus setup and Grafana Dashboard for Confluent Cloud for Flink reporting.</a></li> </ul> <h3 id=compute-pool-monitoring>Compute pool monitoring<a class=headerlink href=#compute-pool-monitoring title="Permanent link">&para;</a></h3> <p>See <a href=https://docs.confluent.io/cloud/current/monitoring/third-party-integration.html#troubleshoot-grafana>Grafana integration</a>.</p> <h3 id=some-common-errors>Some common errors<a class=headerlink href=#some-common-errors title="Permanent link">&para;</a></h3> <ul> <li> <p>Some query with a lot of joins (10+) on static data, do not returns the same results when doind a SELECT from in CC Workspace. This behavior for foreground query, may be possible, as query plan construction may have timedout. When quesry start to be complex and need to process multiple real records and not just some test data, it is recommended to move to INSERT INTO sink_table SELECT ... and then use the Workspace to look at the table inside the sink_table. The query will run in background and may take sometime to deploy, but will run.</p> </li> <li> <p>DML statement failing, or being degraded, or pending can be notified to external system. <a href=https://docs.confluent.io/cloud/current/monitoring/configure-notifications.html#ccloud-notifications>See the notification for CC documentation</a></p> </li> </ul> <h2 id=role-base-access-control>Role Base Access Control<a class=headerlink href=#role-base-access-control title="Permanent link">&para;</a></h2> <p><a href=https://docs.confluent.io/cloud/current/flink/operate-and-deploy/flink-rbac.html>The product documentation</a> goes into sufficient details on how RBAC works for Flink. </p> <ul> <li>Remember some inport facts:<ul> <li>When registering to CC, one org is created with the user who registered. Other users are invited.</li> </ul> </li> </ul> <p>The following table list some classical use case and expected role: | Use Case | Least privilege role needed | | -------- | ----------- | | Create environment | EnvironmentAdmin | | Create compute pool | FlinkAdmin scoped at environment level | | Deploy flink statement | FlinkDeveloper (FlinkAdmin too) | | Create R/W Schemas in SR | DataSteward | | Admin the org | OrganizationAdmin | </p> <p>Examples of Terraform definitions for service accounts, roles, and role binding <a href=https://github.com/jbcodeforce/flink-studies/tree/master/deployment/cc-terraform>cc-terraform for my env</a>.</p> <h2 id=understanding-pricing>Understanding pricing<a class=headerlink href=#understanding-pricing title="Permanent link">&para;</a></h2> <p>The <a href=https://docs.confluent.io/cloud/current/flink/concepts/flink-billing.html#cfu-billing>CFU pricing is here.</a> Price per hour computed by the minute. </p> <p>Some core principals:</p> <ul> <li>Flink SQL runs each statement independently of any others.</li> <li>Not overpay for processing capacity. Pay for what is used. Increment at the minute level.</li> <li>Short live queries cost a real minimum, and can be done in a shared compute pool</li> <li>Long running queries cost is aggregated per hour with minute increment. So a statement starting at 1 CFU for 10 minutes then 3 CFUs for 30 and back to 2 for 10 and 1 for 10 will use 10 + 90 + 20 + 10 = 130 CFUs for the hour.</li> <li>Statement throughput generally scales linearly in the number of CFUs available to a statement.</li> <li>The Max CFU parameter is a just for Budget control</li> </ul> <p>To estimate CFU consumption we need to:</p> <ol> <li>Expected record per second (RPS) / throughput </li> <li>Message size and total number of messages to process</li> <li> <p>Type of SQL, select only, or joins, grouping...</p> <ul> <li>simple 1 to 1 select stateless transformation is determined by how much write volume the sink topic can handle.</li> <li>For Joins, aggregates, ... the way in which a statement must access and maintains the state is more influential than the raw quantity of state.</li> <li>The total of all CFU estimates across the workload will provide a rough approximation of total CFUs required</li> </ul> </li> </ol> <p>Several factors significantly affect statement throughput so pricing:</p> <ul> <li><strong>State Overhead</strong>: The overhead related to maintaining state affects JOINs and aggregations more than the quantity of state itself. </li> <li><strong>Records in topic</strong>: if there some burst in ingress traffic to Kafka topics, then Flink may need more resources for a short time period to process the lag. </li> <li><strong>CPU Load:</strong> The complexity of the operations performed by the statement is a major contributor to CPU load.</li> <li><strong>Minimum CFU Consumption:</strong> Every statement will consume at least 1 CFU, and for most workloads, CFU consumption is directly proportional to the number of statements execute.</li> <li>VM machine type may also impact throughput metrics</li> </ul> <h3 id=scoping-workload>Scoping workload<a class=headerlink href=#scoping-workload title="Permanent link">&para;</a></h3> <ul> <li>Assess the number of record per seconds</li> <li>Be sure to clarrify that Confluent Cloud for Flink is used for streaming not batching. Operations like update, truncate, delete table are not supported.</li> <li>For stateless the attainable throughput of the statement per CFU will generally be determined by how much write volume the sink topic can handle.</li> <li>Most important throughput factor is the State size, its access and management. </li> <li>Statement throughput generally <strong>scales linearly</strong> in the number of CFUs available to a statement.</li> <li>UDF impacts throughtput.</li> <li>For each statement, assess the number of records to process per seconds or minutes. Consider ingress message size and egress message size as SQL may generates less data. Also Windowing will generate less messages too. Joins will impact performance depending if they are static or with time window. </li> <li>Look at Kafka message sizes (bytes) as well as message throughput.</li> </ul> <p>As a base for discussion, 10k record/s per CPU is reachable for simple Flink stateless processing.</p> <h2 id=disaster-recovery>Disaster Recovery<a class=headerlink href=#disaster-recovery title="Permanent link">&para;</a></h2> <ul> <li>CC Flink is a regional, multi-AZ service. </li> <li>In case of Job failure, failed jobs auto-restart using the last known states loaded from the last checkpoint.</li> <li>Checkpoint is used for in-region fault tolerance. Checkpoints capture the state of a Flink job at regular intervals, including Kafka consumer offsets, operator states, and internal timers. In CC checkpoints are done every minute.</li> <li>In case of Cloud Provider failure, there is no protection, for a region lost. To address that, architects need to set up a cross region DR strategy.</li> <li>All Flink DR options first require a DR strategy for Kafka &amp; Schema Registry (SR). It needs to have an exact replication of the data (including offsets) and schemas.</li> <li>On CC, <a href=https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/index.html>cluster link</a> and <a href=https://docs.confluent.io/cloud/current/sr/schema-linking.html>schema link</a> supports data and schema replication.</li> </ul> <p>As any flink solution, the following need to be deeply assessed:</p> <ul> <li>What Flink application and SQL statements to consider in scope of DR?</li> <li>Can Flink's state be recreated? This is driven by the underlying Kafka Clusters RPO and their retention.</li> <li>How long is tolerable to recreate that state? This is driven by the overall RTO. </li> <li>What is the semantic expected by consumer apps? This is driven by consuming apps tolerances. Semantics options are: exactly-once, at-least once (duplicate possible), at-most once (data loss and duplicate possible).</li> <li>Is the Flink job processing deterministic? will a Flink job always output the same results?</li> </ul> <p>A generic view of DR components is presented in following figure:</p> <figure> <img alt src=../diagrams/dr_act_act.drawio.png> </figure> <h3 id=active-active>Active / Active<a class=headerlink href=#active-active title="Permanent link">&para;</a></h3> <p>The approach is to have two identical Flink jobs or pipelines of jobs run in parallel continuously in both regions. They process the same data, with some replication delay in the secondary region.</p> <p>This is recommended for low RTO requirements, with Flink jobs with large states, or solutions requiring Exactly-Once semantics, or when it is critical that the 2 regions have exactly the same data results.</p> <p>To consider:</p> <ul> <li>Setup replication only to the input topics. </li> <li>Mirror configuration like service accounts, RBACs, private networking...</li> <li>Ensure Flink jobs have deterministic query results.</li> <li>Jobs should support out-of-order arrival between input tables.</li> </ul> <h3 id=active-passive>Active / Passive<a class=headerlink href=#active-passive title="Permanent link">&para;</a></h3> <p>Flink jobs are started, in second region, only on failover.</p> <p>This approach is possible for stateless jobs, or when states can be created quickly: Flink Jobs Window Size and time to recompute job state &lt; RTO. Solutions based on at-least once, or at-most-once. Even for stateless jobs, Exactly-Once semantics is not supported.</p> <p>To consider:</p> <ul> <li>More complicated to orchestrate as the process needs to recreate tables and jobs during failover</li> <li>Topic retention &gt; Time window needed to recreate state (dictated by window size or TTL). Without enough retention, results will be wrong, or only subset of queries would work.</li> <li>Any time window and aggregation needs to use event time and not processing time.</li> <li>Setup replication only to the input topics. </li> </ul> <h2 id=some-faqs>Some FAQs<a class=headerlink href=#some-faqs title="Permanent link">&para;</a></h2> <ul> <li>Processing time support? It is better to use event time to ensure results are correct, deterministic and reproductible. Using processing time for windowing operations may lead to non-determnistic results. Processing time may be relevant for temporal joins.</li> <li>Is Hive load/unload function supported? The Flink OSS has this load/unload Hive functions capability, but all those Hive functions are already available in CC Flink.</li> <li>How to add Jar? ADD and REMOVE JAR are meant for testing purposes in OSS Flink. For UDFs, Jars can be uploaded via Confluent Console, CLI, REST API or Terraform.</li> <li>How to manage Catalog and Database? In Confluent Cloud Catalog is a Confluent Environment so no direct management from Flink session. Database is a Kafka cluster so the same logic applies.</li> </ul> <h2 id=vscode-extension>VScode extension<a class=headerlink href=#vscode-extension title="Permanent link">&para;</a></h2> <p><a href=https://github.com/confluentinc/vscode>VScode extension</a> to manage Confluent Cloud or Platform resources. </p> <h2 id=deeper-dive>Deeper dive<a class=headerlink href=#deeper-dive title="Permanent link">&para;</a></h2> <ul> <li><a href=https://github.com/confluentinc/commercial-workshops/tree/master/series-getting-started-with-cc/workshop-flink>Confluent Flink workshop</a> to learn how to build stream processing applications using Apache Flink® on Confluent Cloud.</li> <li><a href=https://github.com/jbcodeforce/shoe-store>Shoe-store workshop</a> with Terraform and SQL demonstration using DataGen.</li> <li><a href=../../coding/flink-sql-1/ >SQL coding practices from this repo.</a> and <a href=../../coding/flink-sql-2/ >this</a>.</li> </ul> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../methodology/coe/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Center of Excellence"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Center of Excellence </div> </div> </a> <a href=../cp-flink/ class="md-footer__link md-footer__link--next" aria-label="Next: Confluent Platform for Flink"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Confluent Platform for Flink </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2026 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["content.code.annotation", "content.code.copy", "content.tooltips", "content.tabs.link", "search.suggest", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> </body> </html>