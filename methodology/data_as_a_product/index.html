<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/flink-studies/methodology/data_as_a_product/ rel=canonical><link href=../../labs/ rel=prev><link href=../../techno/ccloud-flink/ rel=next><link rel=icon href=../../images/logo-blue.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.22"><title>Data as a product - Apache and Confluent Flink Studies</title><link rel=stylesheet href=../../assets/stylesheets/main.84d31ad4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#moving-to-a-data-as-a-product-architecture class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Apache and Confluent Flink Studies" class="md-header__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../../images/flink-header-logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Apache and Confluent Flink Studies </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Data as a product </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../architecture/flink-sql/ class=md-tabs__link> Recipes </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Methodology </a> </li> <li class=md-tabs__item> <a href=../../techno/ccloud-flink/ class=md-tabs__link> Related Technologies </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-tabs__link> EDA </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Apache and Confluent Flink Studies" class="md-nav__button md-logo" aria-label="Apache and Confluent Flink Studies" data-md-component=logo> <img src=../../images/flink-header-logo.svg alt=logo> </a> Apache and Confluent Flink Studies </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/flink-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex=0> <span class=md-ellipsis> Home </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/ class=md-nav__link> <span class=md-ellipsis> Key Concepts </span> </a> </li> <li class=md-nav__item> <a href=../../coding/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/ class=md-nav__link> <span class=md-ellipsis> Flink Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/fitforpurpose/ class=md-nav__link> <span class=md-ellipsis> Fit for purpose </span> </a> </li> <li class=md-nav__item> <a href=../../labs/ class=md-nav__link> <span class=md-ellipsis> Labs-Demos </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/agentic_flink/ class=md-nav__link> <span class=md-ellipsis> Agentic applications </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Recipes </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Recipes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../architecture/flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL concepts </span> </a> </li> <li class=md-nav__item> <a href=../../coding/flink-sql/ class=md-nav__link> <span class=md-ellipsis> Flink SQL coding </span> </a> </li> <li class=md-nav__item> <a href=../../coding/firstapp/ class=md-nav__link> <span class=md-ellipsis> First Java Apps </span> </a> </li> <li class=md-nav__item> <a href=../../coding/udf_sql/ class=md-nav__link> <span class=md-ellipsis> UDFs for SQL </span> </a> </li> <li class=md-nav__item> <a href=../../coding/k8s-deploy/ class=md-nav__link> <span class=md-ellipsis> Kubernetes Deployment </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Manage CC Flink projects </span> </a> </li> <li class=md-nav__item> <a href=../../coding/datastream/ class=md-nav__link> <span class=md-ellipsis> DataStreams </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/cookbook/ class=md-nav__link> <span class=md-ellipsis> Flink Cookbook </span> </a> </li> <li class=md-nav__item> <a href=../../coding/table-api/ class=md-nav__link> <span class=md-ellipsis> Table API </span> </a> </li> <li class=md-nav__item> <a href=../../coding/stateful-func/ class=md-nav__link> <span class=md-ellipsis> Stateful function </span> </a> </li> <li class=md-nav__item> <a href=../../coding/cep/ class=md-nav__link> <span class=md-ellipsis> Complex Event Processing </span> </a> </li> <li class=md-nav__item> <a href=../../coding/terraform/ class=md-nav__link> <span class=md-ellipsis> IaC wt Terraform </span> </a> </li> <li class=md-nav__item> <a href=../../techno/fk-k8s-monitor/ class=md-nav__link> <span class=md-ellipsis> Flink on k8s Monitoring </span> </a> </li> <li class=md-nav__item> <a href=../../labs/ class=md-nav__link> <span class=md-ellipsis> Labs-Demos </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Data as a product </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Data as a product </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#context class=md-nav__link> <span class=md-ellipsis> Context </span> </a> <nav class=md-nav aria-label=Context> <ul class=md-nav__list> <li class=md-nav__item> <a href=#operational-data-and-analytical-data class=md-nav__link> <span class=md-ellipsis> Operational Data and Analytical data </span> </a> </li> <li class=md-nav__item> <a href=#current-challenges class=md-nav__link> <span class=md-ellipsis> Current Challenges </span> </a> </li> <li class=md-nav__item> <a href=#core-principles-for-data-mesh class=md-nav__link> <span class=md-ellipsis> Core principles for Data Mesh </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#a-data-product-approach class=md-nav__link> <span class=md-ellipsis> A data product approach </span> </a> <nav class=md-nav aria-label="A data product approach"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#data-as-a-product class=md-nav__link> <span class=md-ellipsis> Data as a product </span> </a> </li> <li class=md-nav__item> <a href=#elements-of-a-data-product class=md-nav__link> <span class=md-ellipsis> Elements of a Data Product </span> </a> </li> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#motivations-for-moving-to-data-stream-processing class=md-nav__link> <span class=md-ellipsis> Motivations for moving to data stream processing </span> </a> <nav class=md-nav aria-label="Motivations for moving to data stream processing"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#assessment-questions class=md-nav__link> <span class=md-ellipsis> Assessment questions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#migration-context class=md-nav__link> <span class=md-ellipsis> Migration Context </span> </a> </li> <li class=md-nav__item> <a href=#time-condiderations class=md-nav__link> <span class=md-ellipsis> Time condiderations </span> </a> </li> <li class=md-nav__item> <a href=#some-implementation-challenges class=md-nav__link> <span class=md-ellipsis> Some implementation challenges </span> </a> <nav class=md-nav aria-label="Some implementation challenges"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#git-project-organization class=md-nav__link> <span class=md-ellipsis> Git project organization </span> </a> </li> <li class=md-nav__item> <a href=#joins-considerations class=md-nav__link> <span class=md-ellipsis> Joins considerations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#source-of-information-go-deeper class=md-nav__link> <span class=md-ellipsis> Source of information - go deeper </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies/methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/shift_left_utils/ class=md-nav__link> <span class=md-ellipsis> Migrate to real-time processing tools </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/flink_project_demos/c360/spark_project/ class=md-nav__link> <span class=md-ellipsis> A C360 data product demo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Related Technologies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Related Technologies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/ccloud-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Cloud Flink </span> </a> </li> <li class=md-nav__item> <a href=../../techno/cp-flink/ class=md-nav__link> <span class=md-ellipsis> Confluent Platform for Flink </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/kafka/ class=md-nav__link> <span class=md-ellipsis> Kafka Integration </span> </a> </li> <li class=md-nav__item> <a href=../../techno/cc-tableflow/ class=md-nav__link> <span class=md-ellipsis> Confluent TableFlow </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/techno/data/#data-related-technologies class=md-nav__link> <span class=md-ellipsis> Apache Iceberg </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/kafka-studies class=md-nav__link> <span class=md-ellipsis> Kafka-studies </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-studies class=md-nav__link> <span class=md-ellipsis> EDA </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#context class=md-nav__link> <span class=md-ellipsis> Context </span> </a> <nav class=md-nav aria-label=Context> <ul class=md-nav__list> <li class=md-nav__item> <a href=#operational-data-and-analytical-data class=md-nav__link> <span class=md-ellipsis> Operational Data and Analytical data </span> </a> </li> <li class=md-nav__item> <a href=#current-challenges class=md-nav__link> <span class=md-ellipsis> Current Challenges </span> </a> </li> <li class=md-nav__item> <a href=#core-principles-for-data-mesh class=md-nav__link> <span class=md-ellipsis> Core principles for Data Mesh </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#a-data-product-approach class=md-nav__link> <span class=md-ellipsis> A data product approach </span> </a> <nav class=md-nav aria-label="A data product approach"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#data-as-a-product class=md-nav__link> <span class=md-ellipsis> Data as a product </span> </a> </li> <li class=md-nav__item> <a href=#elements-of-a-data-product class=md-nav__link> <span class=md-ellipsis> Elements of a Data Product </span> </a> </li> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#motivations-for-moving-to-data-stream-processing class=md-nav__link> <span class=md-ellipsis> Motivations for moving to data stream processing </span> </a> <nav class=md-nav aria-label="Motivations for moving to data stream processing"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#assessment-questions class=md-nav__link> <span class=md-ellipsis> Assessment questions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#migration-context class=md-nav__link> <span class=md-ellipsis> Migration Context </span> </a> </li> <li class=md-nav__item> <a href=#time-condiderations class=md-nav__link> <span class=md-ellipsis> Time condiderations </span> </a> </li> <li class=md-nav__item> <a href=#some-implementation-challenges class=md-nav__link> <span class=md-ellipsis> Some implementation challenges </span> </a> <nav class=md-nav aria-label="Some implementation challenges"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#git-project-organization class=md-nav__link> <span class=md-ellipsis> Git project organization </span> </a> </li> <li class=md-nav__item> <a href=#joins-considerations class=md-nav__link> <span class=md-ellipsis> Joins considerations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#source-of-information-go-deeper class=md-nav__link> <span class=md-ellipsis> Source of information - go deeper </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=moving-to-a-data-as-a-product-architecture>Moving to a data as a product architecture<a class=headerlink href=#moving-to-a-data-as-a-product-architecture title="Permanent link">&para;</a></h1> <p>This chapter provides a practical overview of current data lake and lakehouse challenges, discusses the implementation of 'data as a product' principles, and demonstrates how real-time streaming can be effectively integrated into modern data architectures.</p> <h2 id=context>Context<a class=headerlink href=#context title="Permanent link">&para;</a></h2> <h3 id=operational-data-and-analytical-data>Operational Data and Analytical data<a class=headerlink href=#operational-data-and-analytical-data title="Permanent link">&para;</a></h3> <p>The classical data landscape is split between operational data, which powers real-time applications, and analytical data, which provides historical insights for decision-making and machine learning. This separation has created complex and fragile data architectures, marked by problematic ETL processes and intricate data pipelines. The challenge lies in effectively bridging these two distinct data planes to ensure seamless data flow and integration.</p> <figure> <img alt src=../diagrams/data_op_data_planes.drawio.png width=700> <figcaption>Two data planes: real-time applications, and analytical data</figcaption> </figure> <p>The initial data platform architecture comprised a database on one side and a data warehouse on the other, with ETL jobs facilitating data movement between them. This setup can lead to bottlenecks, especially when different teams are working on various parts of an application but all relying on the same data source. It might also complicate scalability and flexibility.</p> <p>To address scaling challenges and support unstructured data, the second generation of data platforms, emerging in the mid-2000s, adopted distributed object storage, leading to the development of the Data Lake.</p> <p>The medallion architecture, a three-layered approach, is a common framework for organizing data lakes. This structure, as illustrated in the figure below, is driven by several key motivations:</p> <figure> <img alt src=../diagrams/medallion_arch.drawio.png width=700> <figcaption>Medaillion Architecture</figcaption> </figure> <ul> <li>Leveraging cloud object storage to accommodate large volumes of both structured and unstructured data.</li> <li>Implementing data pipelines to transform data progressively, from raw landing zones to business-level aggregates.</li> <li>Facilitating data management and governance through data cataloging and distributed query tools.</li> <li>Organizing data based on its transformation stage, rather than business domains or specific use cases.</li> </ul> <p>Data product and its extension with <strong>Data Mesh</strong> helps to restructure those two planes with a domain and use case centric approach, and not a technology stack.</p> <h3 id=current-challenges>Current Challenges<a class=headerlink href=#current-challenges title="Permanent link">&para;</a></h3> <p>In Lakehouse or data lake architecture: </p> <ul> <li>We observe complex ETL jobs landscape, with high failure rate.</li> <li>Not all data needs the three layers architecture, but a more service contract type of data usage. Data becoming a product like a microservice.</li> <li>There is a latency issue to get the data, we talk about T + 1 to get fresh data. The + 1 can be one day or one hour, but it has latency that may not what business requirements need.</li> <li>Simple transformations need to be done with the ETL or ELT tool with the predefined staging. Not specific use-case driven implementation of the data retrieval and processing. </li> <li>Data are <strong>pulled</strong> from their sources and between layers. It could be micro-batches, or long-running batches. At the bronze layer, the data are duplicated, and there is minimum of quality control done.</li> <li>In the silver layer the filtering and transformations are also generic with no specific business context.</li> <li>The gold layer includes all data of all use cases. This is where most of the work is done for data preparation and develop higher quality level. This is the layer with a lot of demands from end-user and continuous update and new aggregation developments. </li> <li>This is the final consumer of the data lake gold layer that are pulling the data with specific Service Level Objectives. </li> <li>Data created at the gold level, most likely needs to be reingected to the operational databases to be visible to operation applications. This introduces the concept of <strong>reverse ETL</strong>. </li> <li>Each layer may have dfferent actors responsible to process the data: data platform engineer, analytic engineers and data modelers, and at the application level, the application developers.</li> <li>Storing multiple copies of data across layers inflates cloud storage expenses. Data become quickly stale and unreliable.</li> <li>Constant movement of data through layers results in unnecessary processing and query inefficiencies.</li> <li>The operational estate is also continuously growing, by adding mobile applications, serverless functions, cloud native apps, etc...</li> </ul> <h3 id=core-principles-for-data-mesh>Core principles for Data Mesh<a class=headerlink href=#core-principles-for-data-mesh title="Permanent link">&para;</a></h3> <p>To address the concerns of siloed and incompatible data, while addressing scaling to constant change of data landscape, adding more data source and consumers, adding more transformations and processing resources, the data mesh is based on four core principles:</p> <ol> <li> <p>Domain-oriented decentralized <strong>data ownership</strong> and architecture. The components are the analytical data, the metadata and the computer resources to serve it. Data ownership is linked to the DDD bounded context. For a product management use case, the bounded context of a <code>Product</code>, supports operational APIs and analytical data endpoints to address <em>active users, feature usage, and conversion rates</em>, for example: </p> <p><figure markdown=span> <img alt="Bounded context data product" src=../diagrams/bd_ctx_product.drawio.png width=500> <figcaption>Data as a product - Bounded context</figcaption> </figure></p> <p>Also multiple bounded contexts could be presented via their dependencies to other domain operational and analytical data endpoints.</p> </li> <li> <p><strong>Data as a product</strong>, includes clear scope definition, product ownership and metrics to ensure data quality, user acceptance, lead time for data consumption. Data as a product includes documenting the users, how they access the data, and for what kind of operations. The accountability of the data quality shifts to the source of the data. It encapsulates three structural components: <strong>1/ code</strong> (data pipelines, schema definitions, APIs, event processing, monitoring metrics, access control), <strong>2/ data and metadata</strong> in a polyglot form (events, REST, tables, graphs, batch files...), <strong>3/ infrastructure</strong> (to run code, store data and metadata).</p> <p><figure markdown=span> <img alt=data-product-components src=../diagrams/dp_components.drawio.png> <figcaption>Data as a product: component view</figcaption> </figure></p> </li> <li> <p><strong>Self-serve data infrastructure as a platform</strong>, to enable domain autonomy, as microservices are defined and orchestrated. It includes callable polyglot data storage, data products schema, data pipeline declaration and orchestration, data products lineage, compute and data locality. The capabilities includes 1/ <strong>infrastructure provisioning</strong> via code for storage, service accounts, access policies, server provisioning for running code and jobs, 2/ <strong>data product interface</strong>, declarative interfaces to manage the life cycle of a data product, 3/ <strong>supervision plane</strong> to present the relation between data products, support discovery, build data catalog, to execute semantic query.</p> <p><figure markdown=span> <img alt=DP-infrastructure-platform src=../diagrams/infrastructure_platform.drawio.png> <figcaption>Data as a product: infrastructure platform</figcaption> </figure></p> </li> <li> <p>Federated governance to address interoperability of the data products. This needs to support decentralized and domain self-sovereignty, interoperability through standardization. </p> </li> </ol> <details class="- warning"> <summary>Moving to Kafka and real-time processing is not the full story</summary> <p>Changing the batch pipeline processing technologies to real-time processing using the medallion architecture does not solve the previously mentionned problems. We still need to shift paradign and adopt a data as a product centric architecture. The following diagram illustrates the mediallon layers, done with Flink processing and Kafka topics for storage.</p> <p><figure markdown=span> <img alt src=../diagrams/hl-rt-integration.drawio.png> <figcaption>Real-time intgration</figcaption> </figure></p> <p>Using topics as data record storage and Flink statements for transforming, filtering and enriching to the silver layer, also using kafka topics is the same ETL approach but with different technologies. </p> <p>Another, more detailed view, using Kafka Connectors will look like in the diagram below, where the three layers are using the Kimdall practices of source processing, intermediates and sinks.</p> <p><figure markdown=span> <img alt src=../diagrams/generic_src_to_sink_flow.drawio.png> <figcaption>Generic source to sink pipeline</figcaption> </figure></p> <p>Even if append-logs are part of the data as a product architecture, there are more to address and to organize the component development.</p> </details> <h2 id=a-data-product-approach>A data product approach<a class=headerlink href=#a-data-product-approach title="Permanent link">&para;</a></h2> <p>As seen previously, domains need to host and serve their domain datasets in an easily consumable way, rather than flowing the data from domains into a centrally owned data lake or platform. Dataset from one domain may be consumed by another domains in a format suitable for its own application. Consumer pulls the dataset.</p> <figure> <img alt src=../diagrams/rti_dps.drawio.png> <figcaption>Data product reused by other domains</figcaption> </figure> <p>So developing data as a product means shifting from push and ingest of ETL and ELT processes to serving and pull model across all domains. </p> <h3 id=data-as-a-product>Data as a product<a class=headerlink href=#data-as-a-product title="Permanent link">&para;</a></h3> <p>Data products serve analytical data, they are self-contained, deployable, valuable and exhibit eight characteristics:</p> <ul> <li><strong>Discoverable</strong>: data consumers can easily find the data product for their use case. A common implementation is to have a registry, a data catalogue, of all available data products with their meta information. Domain data products need to register themselves to the catalog.</li> <li><strong>Addressable</strong>: with a unique address accessible programmatically. This implies to define naming convention and may be SDK code.</li> <li><strong>Self describable</strong>: Clear description of the purpose and usage patterns as well as the semantics and syntax. The schema definition and registry are used for that purpose. </li> <li><strong>Trustworthy</strong>: clear definition of the <a href=https://en.wikipedia.org/wiki/Service-level_objective>Service Level Objectives</a> and Service Level Indicators conformance. </li> <li><strong>Native access</strong>: adapt the data access interface to the consumer: APIs, events, SQL views, reports, widgets</li> <li><strong>Composable</strong>: integrate with other data products, for joining, filtering and aggregation. Nedd to define standards for field type formatting, identifying polysemes across different domains, datasets address conventions, common metadata fields, event formats such as CloudEvents. Federated identity may also being used to keep unique identifier cross domain for a business entity.</li> <li><strong>Valuable</strong>: represent a cohesive concept within its domain. Sourced from unstructured, semi-structured and structured data. To maximize value within a data mesh, data products should have narrow, specific definitions, enabling reusable blueprints and efficient management.</li> <li><strong>Secure</strong>: with access control rules and enforcement, and single sign on capability.</li> </ul> <p>To support the implementation of those characteristics, it is relevant to name a <em>domain data product owner</em>, who is also responsible to measure data quality, the decreased lead time of data consumption, and the data user satisfaction, or net promoter score. The most important questions a product owner should be able to answer are:</p> <ol> <li>Who are the data users?</li> <li>How do they use the data?</li> <li>What are the native methods that they are comfortable with to consume the data?</li> </ol> <p>Data products are not data applications, data warehouses, PDF reports, dashboards, tables (without proper metadata), or kafka topics. The data products may, and should be shared using streams, to be able to replay from sources of events and scale the consumption. </p> <h3 id=elements-of-a-data-product>Elements of a Data Product<a class=headerlink href=#elements-of-a-data-product title="Permanent link">&para;</a></h3> <p>The following elements are part of a data product owner to develop and manage, with application developers:</p> <ul> <li>Metadata of what the data product is, human readable, parseable for tool to build and deploy data product to orchestration layer. This includes using naming convention, and poliglot definition. </li> <li>API definition for request-response consumptions</li> <li>Event model definition for asynch consumptions</li> <li>Storage definition, service account, roles and access policies</li> <li>Table definitions</li> <li>Flink statement definitions for deduplication, enrichment, aggregation, and deployment definitions</li> <li>Microservice code implementation, packaging and deployment definitions</li> </ul> <p>All those elements can be defined as code in a git repository or between a gitops repo and a code repository. It is recommended to keep one bounded context per repository.</p> <details class="- info"> <summary>Data lake, lakehouse and data warehouse</summary> <p>Data lake is no more a central piece of the architecture with complex pipelines, they are becoming a node in the data mesh, to expose a dataset. It may not be used as the source of truth is becoming the immutable distributes logs and storage that holds the dataset available for replayability. Datawarehouse for business intelligence is also a node, and consumer of the data product.</p> </details> <h3 id=methodology>Methodology<a class=headerlink href=#methodology title="Permanent link">&para;</a></h3> <p>Defining, designing and implementing data products follow the same principles as other software development and should start by the end goal and use case. This should solidify clear product objectives. Domain discovery is part of the DDD methodology, and in the data product a domain may be more oriented to source and some to consumers. But use cases and what needs to be created as analytical data should be the main goals of the design and implementation activities. Source domain datasets represent the <strong>facts of the business</strong>. The source domain datasets capture the data that is mapped very closely to what the operational systems of their origin, generate.</p> <p>Consumer domain datasets, on the other hand, are built to serve a tightly coupled group of use cases. Distinct from source domain datasets, they undergo more structural modifications as they process source domain events into aggregated formats optimized for a specific access model.</p> <h4 id=formalize-the-use-cases-user-stories>Formalize the use cases / user stories<a class=headerlink href=#formalize-the-use-cases-user-stories title="Permanent link">&para;</a></h4> <p>The following table illustrates some use cases:</p> <style>
table th:first-of-type {
    width: 60%;
}
table th:nth-of-type(2) {
    width: 40%;
}
</style> <table> <thead> <tr> <th>User Story</th> <th>Data as a Product</th> </tr> </thead> <tbody> <tr> <td>As a <strong>marketing strategist</strong>, I need to provide predictive churn scores and customer segmentation based on behavior and demographics. This will allow me to proactively target at-risk customers with personalized retention campaigns and optimize marketing spend.</td> <td><ul><li>Churn probability scores for each customer.</li><li>Customer segments based on churn risk and value.</li> <li>Key factors influencing churn.</li></ul></td> </tr> <tr> <td>As a <strong>product manager</strong>, I need to visualize key product usage metrics and performance indicators. This will enable me to monitor product adoption, identify usage patterns, and make data-driven decisions for product improvements.</td> <td><ul><li>Active users, feature usage, and conversion rates.</li><li>Historical trends and comparisons of product performance.</li><li>Breakdowns of product usage by customer segment</li><li>Alerts for anomalies or significant changes in product usage</li></ul></td> </tr> <tr> <td>As a <strong>supply chain manager</strong>, I need to get real-time visibility into inventory levels, supplier performance, and delivery timelines. This will help me proactively identify potential disruptions, optimize inventory management, and ensure timely product delivery.</td> <td><ul><li>Real-time inventory levels across all warehouses.</li><li>Supplier performance metrics, such as on-time delivery rates and quality scores.</li><li>Predictive alerts for potential stockouts or delivery delays.</li><li>Visualizations of delivery routes and timelines.</li><li>Historical data that can be used to perform trend analysis, and find bottlenecks.</li></ul></td> </tr> <tr> <td>As a <strong>Consultant Director</strong>, I need to be able to continuously access a holistic view of each consultant, including their skill level, matching resume, current training and skill levels, and certification status, so that I can effectively staff projects, identify skill gaps, plan professional development, and ensure compliance.</td> <td><ul><li>Aggregated and real-time data on consultant skill levels</li> <li>Matching resumes (potentially key skills extracted)</li><li>Current training completions and skill levels derived from training</li><li>Certification statuses</li><li>Visualization of skill gaps by practice area or project type</li></ul></td> </tr> </tbody> </table> <p>Using a classical system context diagram for the supply chain management use case, we may define the high level view of a data product as:</p> <figure> <img alt src=../diagrams/dp_sys_ctx.drawio.png> <figcaption>Data as a product: system context view</figcaption> </figure> <p>The skill analysis use case may define the following data product:</p> <ul> <li> <p>Certification Compliance Tracker:</p> <ul> <li>Data: Real-time status of all consultant certifications, including expiration dates and renewal progress.</li> <li>Value Proposition: Ensures the organization maintains necessary certifications for compliance and client engagements, mitigating potential risks and penalties.</li> <li>Potential Features: Automated alerts for upcoming expirations; reporting on certification coverage by practice area or client; integration with certification management platforms.</li> </ul> </li> </ul> <h4 id=using-bounded-context>Using bounded context<a class=headerlink href=#using-bounded-context title="Permanent link">&para;</a></h4> <p>Data as a product is designed with a domain-driven model combined with analytical and operational use cases. </p> <p>The methodology to define data product may be compared to the event-driven microservice adoption. Business, operational application, manages their aggregates but also are responsible to publish the business events, as facts, to share their datasets. Aggregation processing is considered as a service pushing data product to other consumers. The aggregate models make specific queries on other data products and serve the results with SLOs.</p> <p>The design starts by the user input, which are part of a business domain and bounded context. The data may be represented as DDD aggregate with a semantic model. <a href=https://jbcodeforce.github.io/eda-studies/methodology/ddd/#entities-and-value-objects>Entities and Value objects</a> are represented to assess the need to reuse other data product and potentially assess the need for anti-corruption layer. </p> <details class="- info"> <summary>What should be part of a bounded context for data as a product</summary> <p>A Bounded Context should encapsulate everything needed to model and implement a specific business capability or set of related capabilities. This typically includes:</p> <ul> <li><strong>Entities</strong>: Domain objects with identity that persist over time and represent core concepts of the subdomain. Their behavior and attributes are specific to this context.</li> <li><strong>Value Objects</strong>: Immutable objects that describe characteristics of entities. Their meaning is specific to the context.</li> <li><strong>Aggregates</strong>: Clusters of related entities and value objects that are treated as a single unit for data changes. One entity within the aggregate serves as the root and is responsible for maintaining the consistency of the entire aggregate. Transactions should operate on aggregates.</li> <li><strong>Domain Services</strong>: Operations that don't naturally belong to an entity or value object but are still part of the domain logic within this context. They often involve interactions between multiple aggregates or external systems.</li> <li><strong>Domain Events</strong>: Significant occurrences within the domain that the business cares about. They are immutable records of something that has happened and can trigger actions within the same or other bounded contexts.</li> <li><strong>Repositories</strong>: Interfaces for persisting and retrieving aggregates within the bounded context. The actual implementation of the repository might use a specific database technology.</li> <li><strong>Factories</strong>: Objects responsible for creating complex domain objects, often encapsulating complex instantiation logic.</li> <li><strong>Use Cases/Application Services</strong>: (Sometimes considered outside the core domain but within the Bounded Context) These orchestrate interactions between domain objects to fulfill specific user requests or system behaviors. They reside at the application layer and interact with repositories and domain services.</li> <li><strong>Data Transfer Objects (DTOs)</strong>: Objects used to transfer data across boundaries (e.g., between layers or bounded contexts). Their structure is often optimized for transport rather than representing the domain model directly.</li> <li><strong>Infrastructure Concerns</strong>: Code related to persistence, messaging, external service integrations, and UI specific to this bounded context.</li> </ul> </details> <p>In data products, DDD bounded context, translates to defining clear boundaries for the data products, ensuring each product serves a specific business domain. A <code>customer data product</code> and a <code>product inventory data product</code> would be distinct bounded contexts, each with its own data model and terminology.</p> <p>Data pushed to higher consumer are part of the semantic model, and of the event-driven design. Analytics Engineers and Data Modellers building aggregate Data Products know exactly what to collect and what quality metrics to serve. The aggregation may use lean-pull mechanism, focusing on their use case needs only. The data is becoming a product as close to the operational source, so shifting the processing to the left of the architecture. This Shift-Left approach where quality controls, validation, and governance mechanisms are embedded as early in the data lineage map as possible. The consumption patterns are designed as part of the data product, and may include APIs, events, real-time streams or even scheduled batch. </p> <p>Source data domains need to make easily consumable historical snapshots of their datasets available, not just timed events. These snapshots should be aggregated based on a time frame that matches the typical rate of change within their domain.</p> <p>Even though domains now own their datasets instead of a central platform, the essential tasks of cleansing, preparing, aggregating, and serving data persist, as does the use of data pipelines, which are now integrated into domain logic.</p> <figure> <img alt src=../diagrams/bdctx_dp_view.drawio.png> <figcaption>Data product within bounded context</figcaption> </figure> <p>Each domain dataset must establish Service Level Objectives for the quality of the data it provides: timeliness, error rates...</p> <p>Moving from technical data delivery to product thinking requires changes in how organizations approach data management. The data product is decomposed of real-time events exposed on event streams, and aggregated analytical data exposed as serialized files on an object store.</p> <p>New requirements are added to the context of the source semantic model.</p> <h3 id=_1><a class=headerlink href=#_1 title="Permanent link">&para;</a></h3> <h2 id=motivations-for-moving-to-data-stream-processing>Motivations for moving to data stream processing<a class=headerlink href=#motivations-for-moving-to-data-stream-processing title="Permanent link">&para;</a></h2> <p>The Data integration adoption is evolving with new needs to act on real-time data and reduce batch processing cost and complexity. The following table illustrates the pros and cons of data integration practices for two axes: time to insights and data integity</p> <style>
table th:first-of-type {
    width: 20%;
}
table th:nth-of-type(2) {
    width: 40%;
}
table th:nth-of-type(3) {
    width: 40%;
}
</style> <table> <thead> <tr> <th>Time to insights</th> <th></th> <th>Data integrity</th> </tr> </thead> <tbody> <tr> <td></td> <td><strong>Low</strong></td> <td><strong>High</strong></td> </tr> <tr> <td><strong>High</strong></td> <td><strong>Lakehouse or ELT:</strong> <ul><li>+ Self-service</li><li>- Runaway cost</li><li>- No knowledge of data lost</li><li>- complext data governance</li><li>- data silos.</li></ul></td> <td><strong>Data Stream Platform:</strong> <ul><li>+ RT decision making</li><li>+ Operation and analytics on same platform</li><li>+ Single source of truth</li><li>+ Reduced TCO</li><li>+ Governance</li></ul></td> </tr> <tr> <td><strong>Low</strong></td> <td><strong>Hand coding:</strong> <ul><li>+ customized solution specific to needs.</li><li>- Slow</li><li>- difficult to scale</li><li>- opaque</li><li>- challenging governance.</li></ul></td> <td><strong>ETL:</strong><ul><li>+ Rigorous</li><li>+ data model design</li><li>+ governed</li><li>+ reliable</li><li>- Slow</li><li>- Point to point</li><li>- Difficult to scale.</li></ul></td> </tr> </tbody> </table> <h3 id=assessment-questions>Assessment questions<a class=headerlink href=#assessment-questions title="Permanent link">&para;</a></h3> <p>Try to get an understanding of the data integration requirements by looking at:</p> <ul> <li>Current data systems and data producers to a messaging system like Kafka</li> <li>Development time to develop new streaming logic or ETL job</li> <li>What are the different data landing zones and for what purpose. Review zone ownership.</li> <li>Level of Lakehouse adoption and governance, which technology used (Iceberg?)</li> <li>Is there a data loop back from the data lake to the OLTP?</li> <li>Where data cleaning is done?</li> <li>Is there any micro-batching jobs currently done, at which frequency, for which consuners?</li> <li>What data governance used?</li> <li>How data quality control is done?</li> </ul> <h2 id=migration-context>Migration Context<a class=headerlink href=#migration-context title="Permanent link">&para;</a></h2> <p>A direct "lift and shift" approach—where batch SQL scripts are converted to Flink statements on a one-to-one basis—is not recommended. Refactoring is essential, as SQL processing often differs significantly in the cases involving complexity and stateful operators, such as joins.</p> <p>Most of the filtering and selection scripts can be ported 1 to 1. While most stateful processing needs to be refactorized and deeply adapted to better manage states and complexity.</p> <p>There is <a href=https://jbcodeforce.github.io/shift_left_utils/ >a repository</a> with tools to process existing dbt project to find dependencies between tables, use local LLM to do some migrations, and create target pipelines per sink table. </p> <hr> <h2 id=time-condiderations>Time condiderations<a class=headerlink href=#time-condiderations title="Permanent link">&para;</a></h2> <h2 id=some-implementation-challenges>Some implementation challenges<a class=headerlink href=#some-implementation-challenges title="Permanent link">&para;</a></h2> <h3 id=git-project-organization>Git project organization<a class=headerlink href=#git-project-organization title="Permanent link">&para;</a></h3> <p>For closely related Bounded Contexts within the same application we can have a repository with different folders per bounded context.</p> <p>The internal structure of each Bounded Context folder typically follows a layered or modular architecture:</p> <ul> <li>domain/: Contains the core domain logic: entities, value objects, aggregates, domain services, and domain events. This layer should be independent of any infrastructure concerns.</li> <li>application/: Contains use cases or application services that orchestrate interactions with the domain layer to fulfill specific business requirements. It often handles transactions and authorization.</li> <li> <p>infrastructure/: Contains the implementation details for interacting with the outside world:</p> <ul> <li>persistence/: Repository implementations using specific database technologies.</li> <li>messaging/: Implementations for sending and receiving domain events or commands using message queues or kafka topics.</li> <li>external-services/: Clients for interacting with other systems or APIs.</li> </ul> </li> <li> <p>interfaces/ (or api/, web/): Contains the entry points to the Bounded Context, such as REST API controllers, GraphQL resolvers, or UI-specific code. It's responsible for request handling and response formatting, often using DTOs to translate between the interface and the application layer.</p> </li> <li>tests/: Contains unit tests, integration tests, and potentially end-to-end tests for the Bounded Context.</li> <li>shared/ (within a Bounded Context): Might contain utilities or helper classes specific to this Bounded Context.</li> </ul> <p>This structure can be in <code>src/main/java</code> for Java project, or src for python/ Fast API project.</p> <h3 id=joins-considerations>Joins considerations<a class=headerlink href=#joins-considerations title="Permanent link">&para;</a></h3> <p>The SQL, LEFT JOIN, joins records that match and don’t match on the condition specified. For non matching record the left columns are populated with NULL. SQL supports LEFT ANTI JOIN, but not Flink. So one solution in Flink SQL is to use a null filter on the left join condition:</p> <div class="language-sql highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>from</span><span class=w> </span><span class=n>table_left</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=k>left</span><span class=w> </span><span class=k>join</span><span class=w> </span><span class=n>table_right</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=w>    </span><span class=k>on</span><span class=w> </span><span class=n>table_left</span><span class=p>.</span><span class=n>column_used_for_join</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>table_right</span><span class=p>.</span><span class=n>column_used_for_join</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=w>    </span><span class=k>where</span><span class=w> </span><span class=n>table_right</span><span class=p>.</span><span class=n>column_used_for_join</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=k>NULL</span><span class=p>;</span>
</span></code></pre></div> <h2 id=source-of-information-go-deeper>Source of information - go deeper<a class=headerlink href=#source-of-information-go-deeper title="Permanent link">&para;</a></h2> <ul> <li><a href=https://martinfowler.com/articles/designing-data-products.html>Martin Fowler - Designing Data Product</a></li> <li><a href=https://martinfowler.com/articles/data-mesh-principles.html>Data Mesh Principals - Zhamak Dehghani</a></li> <li><a href=https://martinfowler.com/articles/data-monolith-to-mesh.html>How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh - Zhamak Dehghani</a></li> <li><a href=https://www.confluent.io/blog/implementing-streaming-data-products/ >Confluent Blog - Data Products, Data Contracts, and Change Data Capture - Adam Bellemare</a></li> </ul> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../labs/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Labs-Demos"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Labs-Demos </div> </div> </a> <a href=../../techno/ccloud-flink/ class="md-footer__link md-footer__link--next" aria-label="Next: Confluent Cloud Flink"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Confluent Cloud Flink </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2025 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotation", "content.code.copy", "content.tooltips", "content.tabs.link", "search.suggest", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> </body> </html>